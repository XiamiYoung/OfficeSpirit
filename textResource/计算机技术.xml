<?xml version="1.0" encoding="UTF-8"?>
<TextList>
<TextTemplate>
<name/>
<content/>
<bookmark/>
</TextTemplate>
<TextBean UUID="cb72574f58ac42679b3fceda81f2fb39">
<name>标 题: 一键安装双击运行——Java安装程序制作</name>
<content>标 题: 一键安装双击运行——Java安装程序制作
作 者: Jason Du
时 间: 2009-3-23
原 文: http://www.blogjava.net/javapro/archive/2009/03/24/JavaAppSetup.html 

　　对于Java桌面应用来说，比较烦琐的就是安装部署问题，如：客户端是否安装有jre、jre版本、jre在哪里下载、如何用jre启动Java应用等等。不要说刚接触电脑的人，就算是比较熟悉电脑，如果没有接触过Java，面对一个Java应用，如何在Windows下启动它，估计都会折腾半天。所以这个是导致Java桌面应用被一些人所讨厌的最大原因，Java的优势是“一次编写，随处运行”,跨平台特性确实很好，但并不是每个人都需要跨平台，而且有时候JVM平台或版本问题也会造成“一次编写，到处测试”的尴尬。对于固定平台下的Java应用，最好的方式莫过于带着JRE,让用户轻松点击就能运行。下面我们来解决这样的问题。

　　针对windows平台，主要方法是：先将JRE进行精简，再使用工具exe4j 来解决双击运行使用的问题，最后用Inno Setup打包成安装程序, 这样一来，我们的Java应用就和普通的windows应用程序一样了。

本文相关下载

本教程PDF格式文档
http://www.uushare.com/user/javapro/file/1418624
http://www.rayfile.com/files/7840998c-1824-11de-942b-0014221b798a/

本教程示例程序
http://www.uushare.com/user/javapro/file/1418316 
http://www.rayfile.com/files/3ee1f95c-1826-11de-bcfb-0019d11a795f/

exe4j 4.2 注册版
http://www.uushare.com/user/javapro/file/1418327 
http://www.rayfile.com/files/c56bebba-1826-11de-9b55-0019d11a795f/

Inno Setup 汉化增强版 + ISTool汉化 + 反编译套装 + ISFD界面设计汉化
http://www.uushare.com/user/javapro/file/1418305 
http://www.rayfile.com/files/95c91dd9-1826-11de-89b1-0019d11a795f/


一、精简JRE

　　JRE6默认安装大小大约90M，而一般程序只有几M甚至几百K，带JRE运行，感觉非常不合理，分发与网络传输过程也会大受影响。关于JRE的精简参照下面几篇相关文章：

Java程序发布之jre篇
http://www.blogjava.net/gdws/archive/2006/12/25/89898.html

如何制作最小的RCP程序压缩包（包含JRE）
http://www.eclipseworld.org/bbs/read-cec-tid-5777.html

让Java程序带上精简的jre（附工具）
http://glemir.xplore.cn/archives/200

JRE极限精简探求手册[1]——精简一个Swing的即时战略游戏
http://cping1982.blog.51cto.com/601635/129630

Java应用——精简JRE体积的小工具
http://blog.csdn.net/cping1982/archive/2008/09/02/2865198.aspx

JVM rt.jar 精简工具图形外壳 0.1
http://www.blogjava.net/beansoft/archive/2008/12/19/247321.html

可以运行 RCP/Swing 的迷你JRE 6（3.75MB）
http://www.blogjava.net/beansoft/archive/2008/01/18/176353.html

可以运行SWT的精简版JRE 1.4.2_04, 压缩后仅1.3MB
http://www.blogjava.net/beansoft/archive/2007/03/07/102381.html

　　总得来说JRE精简是一个比较复杂的工作，如果不清楚某部分的功能不要轻易进行删减，否则可能产生一些未知的错误。pack200压缩工具在对某些重新打包过的rt.jar文件压缩时会产生错误，如果使用的话一定要注意控制台的输出信息。

二、使用exe4j生成exe可执行文件

　　下面是我的一个完整Java示例程序 —— TestProcessBar。可以看到示例程序已经附带了jre , 下面先使用exe4j给它制作一个exe可执行文件(即图中的TestProcessBar.exe)，并指定我们自带的jre 。


 
以下是exe4j的启动界面，点击Next开始创建配置文件。
 



接着选择要创建的exe文件类型，在这里我们选择第一个，这样其实是为程序创建一个可以双击运行的启动器，可以保证程序仍具有跨平台的特性。如果选择第二个，可以把程序完全编译成exe文件，可以更好的保护你的程序不被反编译。



接下来设置程序的短文件名，源文件夹路径（可以使用exe4j工程文件的相对路径。这里我的exe4j文件保存在launcher目录下，所以使用的源路径为[..]，即上一级目录),以及要生成的exe文件的存放目录，exe存放目录相对路径为源文件夹，这里我把它指定为当前源文件夹。



接下来，可以给我们即将生成的exe文件起一个名字，如我的“TestProcessBar.exe”，还可以给它指定一个ico类型的图标，其它按默认就可以了,如图:


 
这里我们还可以为要生成的exe文件附加一些信息



接下来的这一步，我们需要把程序中所用到的类路径添加上去。然后指定程序的启动类，其它如果没有必要的话，则按默认即可，点击+号添加类路径：


 
基本上我们所需要用到的jar文件都要添加上去，可以逐个添加上去，也可以添加整个文件夹或者使用系统环境变量，为了使程序能够随处运行，强列建议使用相对路径，并且不要使用环境变量。添加好类路径之后回到上一步去选择"Main Class"即可。



接下来先选择我们的程序所需要的jre版本， 然后便是选择我们自带的jre了,这一步不是必须，但是为了更好的分发程序，我们自带了jre, 所以有必要把我们自带的jre指定为首选的运行环境，如图选择Search sequence


 
默认情况下程序会去系统的注册表，环境变量及相关的目录查找jre,因为我们只需要自带的jre,所以这里我把默认的选项移除了（如果觉得有必要的话可以把默认的选项放在自带jre选项的后面，不删除），然后添加我们自己的jre所在的目录路径，点+号开始：


 
这里还是建议使用相对的目录路径：



指定jre所在的目录，如图：



最后我的jre目录路径就是这样的：.\jre


 
下面这一步启动画面，有兴趣的可以自已设置一下。


 
程序最终生成了这个执行文件: TestProcessBar.exe
现在使用它，已经可以正常利用我们自带的jre启动程序了，但是整个程序仍有近19M的大小。
这时候打个压缩包，已经可以进行发布了。但是为了更大的压缩，并制作更加方便易用的程序，下面我们使用Inno Setup进行压缩并制作一个安装包。




三、使用Inno Setup为程序制作打包安装程序

安装后启动脚本向导，如图所示： 
 




这里指定程序的启动文件，即刚才用exe4j创建的exe文件。然后将整个程序目录都包含进去就可以了（这里因为程序中有一些exe4j和inno setup的工程文件，故有所选择），接下来的基本上一直按下一步就可以了，其中要设置一下安装程序的输出目录，直到脚本向导完成







然后执行该脚本即可： 





然后找到Inno Setup的输出目录，就可以看到编译输出后的安装包了，如下图：setup.exe
大小已经压到了6.38M。
 


利用这个就可以快速轻松的安装你的Java桌面应用了。
 



四、总结
　　总体来讲，我们的目的是为了让我们编写出的程序更加的方便易用。通过以上的学习，现在我们已经可以制作出可双击运行、不用用户另装jre的、简单易用的程序安装包。大家可以对jre精简、exe启动器的制作、打包安装进行更深入的学习。本教程中的工具只是做一个抛砖引玉，还有很多类似功能的工具有待大家去研究，最后，希望大家能够制作出属于自己的简单明快的一键式Java程序。

</content>
<bookmark>0</bookmark>
</TextBean><TextBean UUID="b67d7d6ab8524f1395e65c1b3d8cb707">
<name>java 线程总结</name>
<content>在论坛上面常常看到初学者对线程的无可奈何，所以总结出了下面一篇文章，希望对一些正在学习使用java线程的初学者有所帮助。

首先要理解线程首先需要了解一些基本的东西，我们现在所使用的大多数操作系统都属于多任务，分时操作系统。正是由于这种操作系统的出现才有了多线程这个概念。我们使用的windows,linux就属于此列。什么是分时操作系统呢，通俗一点与就是可以同一时间执行多个程序的操作系统，在自己的电脑上面，你是不是一边听歌，一边聊天还一边看网页呢？但实际上，并不上cpu在同时执行这些程序，cpu只是将时间切割为时间片，然后将时间片分配给这些程序，获得时间片的程序开始执行，不等执行完毕，下个程序又获得时间片开始执行，这样多个程序轮流执行一段时间，由于现在cpu的高速计算能力，给人的感觉就像是多个程序在同时执行一样。
一般可以在同一时间内执行多个程序的操作系统都有进程的概念.一个进程就是一个执行中的程序,而每一个进程都有自己独立的一块内存空间,一组系统资源.在进程概念中,每一个进程的内部数据和状态都是完全独立的.因此可以想像创建并执行一个进程的系统开像是比较大的，所以线程出现了。在java中，程序通过流控制来执行程序流,程序中单个顺序的流控制称为线程,多线程则指的是在单个程序中可以同时运行多个不同的线程,执行不同的任务.多线程意味着一个程序的多行语句可以看上去几乎在同一时间内同时运行.（你可以将前面一句话的程序换成进程，进程是程序的一次执行过程,是系统运行程序的基本单位）

线程与进程相似,是一段完成某个特定功能的代码,是程序中单个顺序的流控制;但与进程不同的是,同类的多个线程是共享一块内存空间和一组系统资源,而线程本身的数据通常只有微处理器的寄存器数据,以及一个供程序执行时使用的堆栈.所以系统在产生一个线程,或者在各个线程之间切换时,负担要比进程小的多,正因如此,线程也被称为轻负荷进程(light-weight process).一个进程中可以包含多个线程.

多任务是指在一个系统中可以同时运行多个程序,即有多个独立运行的任务,每个任务对应一个进程，同进程一样,一个线程也有从创建,运行到消亡的过程,称为线程的生命周期.用线程的状态(state)表明线程处在生命周期的哪个阶段.线程有创建,可运行,运行中,阻塞,死亡五中状态.通过线程的控制与调度可使线程在这几种状态间转化每个程序至少自动拥有一个线程,称为主线程.当程序加载到内存时,启动主线程.

[线程的运行机制以及调度模型] 
java中多线程就是一个类或一个程序执行或管理多个线程执行任务的能力，每个线程可以独立于其他线程而独立运行，当然也可以和其他线程协同运行，一个类控制着它的所有线程，可以决定哪个线程得到优先级，哪个线程可以访问其他类的资源，哪个线程开始执行，哪个保持休眠状态。
下面是线程的机制图：


线程的状态表示线程正在进行的活动以及在此时间段内所能完成的任务.线程有创建,可运行,运行中,阻塞,死亡五中状态.一个具有生命的线程,总是处于这五种状态之一：
1.创建状态
使用new运算符创建一个线程后,该线程仅仅是一个空对象,系统没有分配资源,称该线程处于创建状态(new thread)
2.可运行状态
使用start()方法启动一个线程后,系统为该线程分配了除CPU外的所需资源,使该线程处于可运行状态(Runnable)
3.运行中状态
Java运行系统通过调度选中一个Runnable的线程,使其占有CPU并转为运行中状态(Running).此时,系统真正执行线程的run()方法.
4.阻塞状态
一个正在运行的线程因某种原因不能继续运行时,进入阻塞状态(Blocked)
5.死亡状态
线程结束后是死亡状态(Dead)

同一时刻如果有多个线程处于可运行状态,则他们需要排队等待CPU资源.此时每个线程自动获得一个线程的优先级(priority),优先级的高低反映线程的重要或紧急程度.可运行状态的线程按优先级排队,线程调度依据优先级基础上的"先到先服务"原则.
线程调度管理器负责线程排队和CPU在线程间的分配,并由线程调度算法进行调度.当线程调度管理器选种某个线程时,该线程获得CPU资源而进入运行状态.

线程调度是先占式调度,即如果在当前线程执行过程中一个更高优先级的线程进入可运行状态,则这个线程立即被调度执行.先占式调度分为:独占式和分时方式.
独占方式下,当前执行线程将一直执行下去,直 到执行完毕或由于某种原因主动放弃CPU,或CPU被一个更高优先级的线程抢占
分时方式下,当前运行线程获得一个时间片,时间到时,即使没有执行完也要让出CPU,进入可运行状态,等待下一个时间片的调度.系统选中其他可运行状态的线程执行
分时方式的系统使每个线程工作若干步,实现多线程同时运行

另外请注意下面的线程调度规则（如果有不理解，不急，往下看）：
①如果两个或是两个以上的线程都修改一个对象，那么把执行修改的方法定义为被同步的（Synchronized）,如果对象更新影响到只读方法，那么只度方法也应该定义为同步的
②如果一个线程必须等待一个对象状态发生变化，那么它应该在对象内部等待，而不是在外部等待，它可以调用一个被同步的方法，并让这个方法调用wait()
③每当一个方法改变某个对象的状态的时候，它应该调用notifyAll()方法，这给等待队列的线程提供机会来看一看执行环境是否已发生改变
④记住wait(),notify(),notifyAll()方法属于Object类，而不是Thread类，仔细检查看是否每次执行wait()方法都有相应的notify()或notifyAll()方法，且它们作用与相同的对象 在java中每个类都有一个主线程，要执行一个程序，那么这个类当中一定要有main方法，这个man方法也就是java class中的主线程。你可以自己创建线程，有两种方法，一是继承Thread类，或是实现Runnable接口。一般情况下，最好避免继承，因为java中是单根继承，如果你选用继承，那么你的类就失去了弹性，当然也不能全然否定继承Thread,该方法编写简单,可以直接操作线程,适用于单重继承情况。至于选用那一种，具体情况具体分析。


eg.继承Thread

public class MyThread_1 extends Thread{public void run(){//some code }}

eg.实现Runnable接口

public class MyThread_2 implements Runnable{public void run(){//some code }}


当使用继承创建线程，这样启动线程：

new MyThread_1().start()

当使用实现接口创建线程，这样启动线程：

new Thread(new MyThread_2()).start()

注意，其实是创建一个线程实例，并以实现了Runnable接口的类为参数传入这个实例，当执行这个线程的时候，MyThread_2中run里面的代码将被执行。
下面是完成的例子：


public class MyThread implements Runnable{ public void run(){ System.out.println("My Name is "+Thread.currentThread().getName()); } public static void main(String[] args){new Thread(new MyThread()).start(); }} 


执行后将打印出：
My Name is Thread-0

你也可以创建多个线程，像下面这样

new Thread(new MyThread()).start();new Thread(new MyThread()).start();new Thread(new MyThread()).start();


那么会打印出：
My Name is Thread-0
My Name is Thread-1
My Name is Thread-2

看了上面的结果，你可能会认为线程的执行顺序是依次执行的，但是那只是一般情况，千万不要用以为是线程的执行机制；影响线程执行顺序的因素有几点：首先看看前面提到的优先级别



public class MyThread implements Runnable{ public void run(){ System.out.println("My Name is "+Thread.currentThread().getName()); } public static void main(String[] args){Thread t1=new Thread(new MyThread());Thread t2=new Thread(new MyThread());Thread t3=new Thread(new MyThread());t2.setPriority(Thread.MAX_PRIORITY);//赋予最高优先级t1.start();t2.start();t3.start();}} 

再看看结果：
My Name is Thread-1
My Name is Thread-0
My Name is Thread-2


线程的优先级分为10级，分别用1到10的整数代表，默认情况是5。上面的t2.setPriority(Thread.MAX_PRIORITY)等价与t2.setPriority(10）
然后是线程程序本身的设计，比如使用sleep,yield,join，wait等方法（详情请看JDKDocument)


public class MyThread implements Runnable{ public void run(){ try{int sleepTime=(int)(Math.random()*100);//产生随机数字，Thread.currentThread().sleep(sleepTime);//让其休眠一定时间，时间又上面sleepTime决定//public static void sleep(long millis)throw InterruptedException （API）System.out.println(Thread.currentThread().getName()+" 睡了 "+sleepTime);}catch(InterruptedException ie)//由于线程在休眠可能被中断，所以调用sleep方法的时候需要捕捉异常{ie.printStackTrace();} } public static void main(String[] args){Thread t1=new Thread(new MyThread());Thread t2=new Thread(new MyThread());Thread t3=new Thread(new MyThread());t1.start();t2.start();t3.start();}}

执行后观察其输出：

Thread-0 睡了 11
Thread-2 睡了 48
Thread-1 睡了 69



上面的执行结果是随机的，再执行很可能出现不同的结果。由于上面我在run中添加了休眠语句，当线程休眠的时候就会让出cpu，cpu将会选择执行处于runnable状态中的其他线程，当然也可能出现这种情况，休眠的Thread立即进入了runnable状态，cpu再次执行它。
[线程组概念]
线程是可以被组织的，java中存在线程组的概念，每个线程都是一个线程组的成员,线程组把多个线程集成为一个对象,通过线程组可以同时对其中的多个线程进行操作,如启动一个线程组的所有线程等.Java的线程组由java.lang包中的Thread——Group类实现.
ThreadGroup类用来管理一组线程,包括:线程的数目,线程间的关系,线程正在执行的操作,以及线程将要启动或终止时间等.线程组还可以包含线程组.在Java的应用程序中,最高层的线程组是名位main的线程组,在main中还可以加入线程或线程组,在mian的子线程组中也可以加入线程和线程组,形成线程组和线程之间的树状继承关系。像上面创建的线程都是属于main这个线程组的。
借用上面的例子，main里面可以这样写：


public static void main(String[] args){/***************************************ThreadGroup(String name) ThreadGroup(ThreadGroup parent, String name) ***********************************/ThreadGroup group1=new ThreadGroup("group1");ThreadGroup group2=new ThreadGroup(group1,"group2");Thread t1=new Thread(group2,new MyThread());Thread t2=new Thread(group2,new MyThread());Thread t3=new Thread(group2,new MyThread());t1.start();t2.start();t3.start();}


线程组的嵌套，t1,t2,t3被加入group2,group2加入group1。
另外一个比较多就是关于线程同步方面的，试想这样一种情况，你有一笔存款在银行，你在一家银行为你的账户存款，而你的妻子在另一家银行从这个账户提款，现在你有1000块在你的账户里面。你存入了1000，但是由于另一方也在对这笔存款进行操作，人家开始执行的时候只看到账户里面原来的1000元，当你的妻子提款1000元后，你妻子所在的银行就认为你的账户里面没有钱了，而你所在的银行却认为你还有2000元。
看看下面的例子：


class BlankSaving //储蓄账户{private static int money=10000;public void add(int i){money=money+i;System.out.println("Husband 向银行存入了 [￥"+i+"]");}public void get(int i){money=money-i;System.out.println("Wife 向银行取走了 [￥"+i+"]");if(money&amp;lt;0)System.out.println("余额不足！"); }public int showMoney(){return money;}} class Operater implements Runnable{String name;BlankSaving bs;public Operater(BlankSaving b,String s){name=s;bs=b;}public static void oper(String name,BlankSaving bs){if(name.equals("husband")){try{for(int i=0;i&amp;lt;10;i++){Thread.currentThread().sleep((int)(Math.random()*300));bs.add(1000);}}catch(InterruptedException e){}}else{try{for(int i=0;i&amp;lt;10;i++){Thread.currentThread().sleep((int)(Math.random()*300));bs.get(1000);}}catch(InterruptedException e){}}}public void run(){oper(name,bs);} }public class BankTest {public static void main(String[] args)throws InterruptedException{BlankSaving bs=new BlankSaving();Operater o1=new Operater(bs,"husband");Operater o2=new Operater(bs,"wife");Thread t1=new Thread(o1);Thread t2=new Thread(o2);t1.start();t2.start();Thread.currentThread().sleep(500);}}


下面是其中一次的执行结果：



---------first--------------
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Husband 向银行存入了 [￥1000]

看到了吗，这可不是正确的需求，在husband还没有结束操作的时候，wife就插了进来，这样很可能导致意外的结果。解决办法很简单，就是将对数据进行操作方法声明为synchronized,当方法被该关键字声明后，也就意味着，如果这个数据被加锁，只有一个对象得到这个数据的锁的时候该对象才能对这个数据进行操作。也就是当你存款的时候，这笔账户在其他地方是不能进行操作的，只有你存款完毕，银行管理人员将账户解锁，其他人才能对这个账户进行操作。
修改public static void oper(String name,BlankSaving bs)为public static void oper(String name,BlankSaving bs)，再看看结果:

Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Husband 向银行存入了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]
Wife 向银行取走了 [￥1000]



当丈夫完成操作后，妻子才开始执行操作，这样的话，对共享对象的操作就不会有问题了。
[wait and notify]
你可以利用这两个方法很好的控制线程的执行流程，当线程调用wait方法后，线程将被挂起，直到被另一线程唤醒（notify）或则是如果wait方法指定有时间得话，在没有被唤醒的情况下，指定时间时间过后也将自动被唤醒。但是要注意一定，被唤醒并不是指马上执行，而是从组塞状态变为可运行状态，其是否运行还要看cpu的调度。
事例代码：


class MyThread_1 extends Thread{Object lock;public MyThread_1(Object o){lock=o;}public void run(){try{synchronized(lock){System.out.println("Enter Thread_1 and wait");lock.wait();System.out.println("be notified");}}catch(InterruptedException e){}}}class MyThread_2 extends Thread{Object lock;public MyThread_2(Object o){lock=o;}public void run(){synchronized(lock){System.out.println("Enter Thread_2 and notify");lock.notify();}}}public class MyThread{ public static void main(String[] args){int[] in=new int[0];//noticeMyThread_1 t1=new MyThread_1(in);MyThread_2 t2=new MyThread_2(in);t1.start();t2.start();}}



执行结果如下：
Enter Thread_1 and wait
Enter Thread_2 and notify
Thread_1 be notified

可能你注意到了在使用wait and notify方法得时候我使用了synchronized块来包装这两个方法，这是由于调用这两个方法的时候线程必须获得锁，也就是上面代码中的lock[]，如果你不用synchronized包装这两个方法的得话，又或则锁不一是同一把，比如在MyThread_2中synchronized(lock)改为synchronized(this),那么执行这个程序的时候将会抛出java.lang.IllegalMonitorStateException执行期异常。另外wait and notify方法是Object中的，并不在Thread这个类中。最后你可能注意到了这点：int[] in=new int[0];为什么不是创建new Object而是一个0长度的数组，那是因为在java中创建一个0长度的数组来充当锁更加高效。

Thread作为java中一重要组成部分，当然还有很多地方需要更深刻的认识，上面只是对Thread的一些常识和易错问题做了一个简要的总结，若要真正的掌握java的线程，还需要自己多做总结&lt;/content&gt;
        </content>
<bookmark>0</bookmark>
</TextBean><TextBean UUID="fa091ff570f2409fa3b345668924f0eb">
<name>JTable常见用法</name>
<content>一.创建表格控件的各种方式:
1)  调用无参构造函数.
JTable table = new JTable();
2)  以表头和表数据创建表格.
Object[][] cellData = {{"row1-col1", "row1-col2"},{"row2-col1", "row2-col2"}};
String[] columnNames = {"col1", "col2"};
   
JTable table = new JTable(cellData, columnNames);
3)  以表头和表数据创建表格,并且让表单元格不可改.
String[] headers = { "表头一", "表头二", "表头三" };
Object[][] cellData = null;

DefaultTableModel model = new DefaultTableModel(cellData, headers) {

  public boolean isCellEditable(int row, int column) {
    return false;
  }
};

table = new JTable(model);
二.对表格列的控制
1) 设置列不可随容器组件大小变化自动调整宽度.
table.setAutoResizeMode(JTable.AUTO_RESIZE_OFF);
2) 限制某列的宽度.
TableColumn firsetColumn = table.getColumnModel().getColumn(0);
firsetColumn.setPreferredWidth(30);
firsetColumn.setMaxWidth(30);
firsetColumn.setMinWidth(30);
3) 设置当前列数.
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();
int count=5;
tableModel.setColumnCount(count);
4) 取得表格列数
int cols = table.getColumnCount();
5) 添加列
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();
tableModel.addColumn("新列名");
6) 删除列
table.removeColumn(table.getColumnModel().getColumn(columnIndex));// columnIndex是要删除的列序号
三.对表格行的控制
1) 设置行高
table.setRowHeight(20);
2) 设置当前航数
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();
int n=5;
tableModel.setRowCount(n);
3) 取得表格行数
int rows = table.getRowCount();

4) 添加表格行
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();
tableModel.addRow(new Object[]{"sitinspring", "35", "Boss"});
5) 删除表格行
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();
model.removeRow(rowIndex);// rowIndex是要删除的行序号
四.存取表格单元格的数据
1) 取单元格数据
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();
String cellValue=(String) tableModel.getValueAt(row, column);// 取单元格数据,row是行号,column是列号
2) 填充数据到表格.
注:数据是Member类型的链表,Member类如下:
public class Member{
    // 名称
    private String name;
   
    // 年龄
    private String age;
   
    // 职务
    private String title;
}
填充数据的代码:
public void fillTable(List&lt;Member&gt; members){
  DefaultTableModel tableModel = (DefaultTableModel) table
  .getModel();
  tableModel.setRowCount(0);// 清除原有行
 
  // 填充数据
  for(Member member:members){
    String[] arr=new String[3];
    arr[0]=member.getName();
    arr[1]=member.getAge();
    arr[2]=member.getTitle();
   
    // 添加数据到表格
    tableModel.addRow(arr);
  }
 
  // 更新表格
  table.invalidate();
}
2) 取得表格中的数据
public List&lt;Member&gt; getShowMembers(){
  List&lt;Member&gt; members=new ArrayList&lt;Member&gt;();
 
  DefaultTableModel tableModel = (DefaultTableModel) table
  .getModel();
 
  int rowCount=tableModel.getRowCount();
 
  for(int i=0;i&lt;rowCount;i++){
    Member member=new Member();
   
    member.setName((String)tableModel.getValueAt(i, 0));// 取得第i行第一列的数据
    member.setAge((String)tableModel.getValueAt(i, 1));// 取得第i行第二列的数据
    member.setTitle((String)tableModel.getValueAt(i, 2));// 取得第i行第三列的数据
   
    members.add(member);
  }
 
  return members;
}
五.取得用户所选的行
1) 取得用户所选的单行
int selectRows=table.getSelectedRows().length;// 取得用户所选行的行数
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();

if(selectRows==1){
  int selectedRowIndex = table.getSelectedRow(); // 取得用户所选单行 
 
  .// 进行相关处理
}
2) 取得用户所选的多行
int selectRows=table.getSelectedRows().length;// 取得用户所选行的行数
DefaultTableModel tableModel = (DefaultTableModel) table.getModel();

if(selectRows&gt;1)
  int[] selRowIndexs=table.getSelectedRows();// 用户所选行的序列
 
  for(int i=0;i&lt;selRowIndexs.length;i++){
    // 用tableModel.getValueAt(row, column)取单元格数据
    String cellValue=(String) tableModel.getValueAt(i, 1);
  }
}
六.添加表格的事件处理
view.getTable().addMouseListener(new MouseListener() {
  public void mousePressed(MouseEvent e) {
    // 鼠标按下时的处理
  }

  public void mouseReleased(MouseEvent e) {
    // 鼠标松开时的处理
  }

  public void mouseEntered(MouseEvent e) {
    // 鼠标进入表格时的处理
  }

  public void mouseExited(MouseEvent e) {
    // 鼠标退出表格时的处理
  }

  public void mouseClicked(MouseEvent e) {
    // 鼠标点击时的处理
  }
});


</content>
<bookmark>2352</bookmark>
</TextBean><TextBean UUID="b272dc9a52bf4339a9d3dffde4d11a88">
<name>垂直柱状图 </name>
<content>http://book.csdn.net/bookfiles/201/1002019669.shtml</content>
<bookmark>0</bookmark>
</TextBean><TextBean UUID="8add0da3e7124f699714192c434f9f98">
<name>ORACLE的隔离级别 </name>
<content>隔离级别（isolation level）

 

l         隔离级别定义了事务与事务之间的隔离程度。

l         隔离级别与并发性是互为矛盾的：隔离程度越高，数据库的并发性越差；隔离程度越低，数据库的并发性越好。

l         ANSI/ISO SQL92标准定义了一些数据库操作的隔离级别：

l          未提交读（read uncommitted）

l          提交读（read committed）

l          重复读（repeatable read）

l          序列化（serializable）

l         通过一些现象，可以反映出隔离级别的效果。这些现象有：

l          更新丢失（lost update）：当系统允许两个事务同时更新同一数据是，发生更新丢失。

l          脏读（dirty read）：当一个事务读取另一个事务尚未提交的修改时，产生脏读。

l          非重复读（nonrepeatable read）：同一查询在同一事务中多次进行，由于其他提交事务所做的修改或删除，每次返回不同的结果集，此时发生非重复读。(A transaction rereads data it has previously read and finds that another committed transaction has modified or deleted the data.  )

l          幻像（phantom read）：同一查询在同一事务中多次进行，由于其他提交事务所做的插入操作，每次返回不同的结果集，此时发生幻像读。(A transaction reexecutes a query returning a set of rows that satisfies a search condition and finds that another committed transaction has inserted additional rows that satisfy the condition.  )

l         下面是隔离级别及其对应的可能出现或不可能出现的现象

 
 		Read uncommitted	Read committed	Repeatable read	Serializable
Dirty Read  		 Possible		 Not possible		 Not possible		 Not possible
 NonRepeatable Read  	 Possible		 Possible		 Not possible		 Not possible
 Phantom Read  	 Possible		 Possible		 Possible		 Not possible


ORACLE的隔离级别

 

l         ORACLE提供了SQL92标准中的read committed和serializable，同时提供了非SQL92标准的read-only。

l          read committed：

l         这是ORACLE缺省的事务隔离级别。

l         事务中的每一条语句都遵从语句级的读一致性。

l         保证不会脏读；但可能出现非重复读和幻像。

l          serializable：

l         简单地说，serializable就是使事务看起来象是一个接着一个地顺序地执行。

l         仅仅能看见在本事务开始前由其它事务提交的更改和在本事务中所做的更改。

l         保证不会出现非重复读和幻像。

l         Serializable隔离级别提供了read-only事务所提供的读一致性（事务级的读一致性），同时又允许DML操作。

l         如果有在serializable事务开始时未提交的事务在serializable事务结束之前修改了serializable事务将要修改的行并进行了提交，则serializable事务不会读到这些变更，因此发生无法序列化访问的错误。（换一种解释方法：只要在serializable事务开始到结束之间有其他事务对serializable事务要修改的东西进行了修改并提交了修改，则发生无法序列化访问的错误。）

l         If a serializable transaction contains data manipulation language (DML) that attempts to update any resource that may have been updated in a transaction uncommitted at the start of the serializable transaction, （并且修改在后来被提交而没有回滚），then the DML statement fails. 返回的错误是ORA-08177: Cannot serialize access for this transaction。

l         ORACLE在数据块中记录最近对数据行执行修改操作的N个事务的信息，目的是确定是否有在本事务开始时未提交的事务修改了本事务将要修改的行。具体见英文：Oracle permits a serializable transaction to modify a data row only if it can determine that prior changes to the row were made by transactions that had committed when the serializable transaction began. To make this determination efficiently, Oracle uses control information stored in the data block that indicates which rows in the block contain committed and uncommitted changes. In a sense, the block contains a recent history of transactions that affected each row in the block. The amount of history that is retained is controlled by the INITRANS parameter of CREATE TABLE and ALTER TABLE. Under some circumstances, Oracle may have insufficient history information to determine whether a row has been updated by a "too recent" transaction. This can occur when many transactions concurrently modify the same data block, or do so in a very short period. You can avoid this situation by setting higher values of INITRANS for tables that will experience many transactions updating the same blocks. Doing so will enable Oracle to allocate sufficient storage in each block to record the history of recent transactions that accessed the block. 

l          The INITRANS Parameter：Oracle stores control information in each data block to manage access by concurrent transactions. Therefore, if you set the transaction isolation level to serializable, you must use the ALTER TABLE command to set INITRANS to at least 3. This parameter will cause Oracle to allocate sufficient storage in each block to record the history of recent transactions that accessed the block. Higher values should be used for tables that will undergo many transactions updating the same blocks. 

l          read-only：

l         遵从事务级的读一致性，仅仅能看见在本事务开始前由其它事务提交的更改。

l         不允许在本事务中进行DML操作。

l         read only是serializable的子集。它们都避免了非重复读和幻像。区别是在read only中是只读；而在serializable中可以进行DML操作。

l         Export with CONSISTENT = Y sets the transaction to read-only.

l          read committed和serializable的区别和联系：

l         事务1先于事务2开始，并保持未提交状态。事务2想要修改正被事务1修改的行。事务2等待。如果事务1回滚，则事务2（不论是read committed还是serializable方式）进行它想要做的修改。如果事务1提交，则当事务2是read committed方式时，进行它想要做的修改；当事务2是serializable方式时，失败并报错“Cannot serialize access”，因为事务2看不见事务1提交的修改，且事务2想在事务一修改的基础上再做修改。具体见英文：Both read committed and serializable transactions use row-level locking, and both will wait if they try to change a row updated by an uncommitted concurrent transaction. The second transaction that tries to update a given row waits for the other transaction to commit or roll back and release its lock. If that other transaction rolls back, the waiting transaction (regardless of its isolation mode) can proceed to change the previously locked row, as if the other transaction had not existed. However, if the other (blocking) transaction commits and releases its locks, a read committed transaction proceeds with its intended update. A serializable transaction, however, fails with the error "Cannot serialize access", because the other transaction has committed a change that was made since the serializable transaction began. 

l         read committed和serializable可以在ORACLE并行服务器中使用。

l          关于SET TRANSACTION READ WRITE：read write和read committed 应该是一样的。在读方面，它们都避免了脏读，但都无法实现重复读。虽然没有文档说明read write在写方面与read committed一致，但显然它在写的时候会加排他锁以避免更新丢失。在加锁的过程中，如果遇到待锁定资源无法锁定，应该是等待而不是放弃。这与read committed一致。

l         语句级的读一致性

l          ORACLE保证语句级的读一致性，即一个语句所处理的数据集是在单一时间点上的数据集，这个时间点是这个语句开始的时间。

l          一个语句看不见在它开始执行后提交的修改。

l          对于DML语句，它看不见由自己所做的修改，即DML语句看见的是它本身开始执行以前存在的数据。

l         事务级的读一致性

l          事务级的读一致性保证了可重复读，并保证不会出现幻像。

l         设置隔离级别

l          设置一个事务的隔离级别

l         SET TRANSACTION ISOLATION LEVEL READ COMMITTED; 

l         SET TRANSACTION ISOLATION LEVEL SERIALIZABLE; 

l         SET TRANSACTION READ ONLY; 

l         设置增个会话的隔离级别

l         ALTER SESSION SET ISOLATION_LEVEL SERIALIZABLE; 

l         ALTER SESSION SET ISOLATION_LEVEL READ COMMITTED; 

</content>
<bookmark>1555</bookmark>
</TextBean><TextBean UUID="30e0ebfcca1544329be634f6c36df56b">
<name>IO、文件、NIO</name>
<content>（这一个章节将讲到Java里面比较重要的一个章节，这里说一句抱歉，因为最近换工作的原因，一直没有时间继续书写教程，不过接下来我会一直坚持写下去的哈，希望大家能够支持。这个章节主要涉及到常用的文件读写，包括高级的文件IO内容——java.nio，因为这些内容在如今的一些项目里面也属于相当常见的一部分，如果有什么遗漏或者笔误的话，希望读者来Email告知：silentbalanceyh@126.com，谢谢！这一部分篇幅可能比前边章节长很多，也是为了保证能够将Java里面IO和文件操作部分内能写的都写入，如果有遗漏希望读者来Email，概念上有混淆的地方请告知，里面有些内容参考了一些原文数据进行了翻译以及思考注解。）
本章目录： 


1.IO类相关内容
2.文件和目录
3.文件高级操作
【Jar文档的读写(.jar)】
　　JAR文件介绍：
　　JAR文件格式是以流行的ZIP文件格式为基础，用于将许多文件聚集压缩到一个文件里面，与ZIP文件不同的是，JAR文件不仅用于压缩和发布，而且还用于部署和封装库、组件和插件程序，并可被像编译器和JVM这样的工具直接使用。在JAR文件中包含特殊的文件，如manifests和部署描述符，用来只是工具如何处理特定的JAR文件。
　　JAR文件的作用如下：
用于发布和使用类库 
作为应用程序和扩展的构建单元 
作为组件、applet或者插件程序的部署单位 
用于打包与组件相关联的辅助资源 
　　JAR文件格式提供了许多优势和功能，其中很多是传统的压缩格式如ZIP或者TAR所没有提供的，包括：
安全性：可以对JAR文件内容加上数字化签名，这样，能够识别签名的工具就可以有选择地为您授予软件安全特权，这是其他文件做不到的，它还可以检测代码是否被篡改过 
减少下载时间：如果一个Applet捆绑到一个JAR文件中，那么浏览器就可以在一个HTTP事务中下载这个Applet的类文件和相关资源，而不是对每一个文件打开一个新连接 
压缩：JAR格式允许您压缩文件以提高存储效率 
传输平台扩展：Java扩展框架（Java Extensions Framework）提供向Java核心平台添加功能的方法，这些扩展是用JAR文件打包的（Java 3D和JavaMail就是扩展的例子） 
包密封：存储在JAR文件中的包可以选择进行密封，以增强版本一致性和安全性，密封一个包意味着包中的所有类都必须在同一个JAR文件中找到 
包版本控制：一个JAR文件可以包含有关它所包含的文件的数据，如厂商和版本信息 
可移植性：处理JAR文件的机制就是Java核心平台API的标准部分 
　　META-INF目录：
　　大多数JAR文件包含一个META-INF目录，它用于存储包和扩展的配置数据，如安全性和版本信息，Java 2平台识别并解释META-INF目录中的下述文件和目录，以便配置应用程序、扩展应用和类装载器：
MANIFEST.MF：这个manifest文件定义了与扩展和包相关的数据源 
INDEX.LIST：这个文件由jar工具的新选项-i生成，它包含在应用程序或者扩展中定义的包的位置信息，它是JarIndex实现的一部分，并且由类装载器装载过程。 
XXX.SF：这个是JAR文件的签名文件。占位符XXX表示了签名者 
XXX.DSA：与签名文件相关联的签名程序块文件，它存储了用于签名JAR文件的公共签名 
　　Pack200类：
　　Pack200类的全名为：java.util.jar.Pack200，这个类是JDK 1.5过后才有的类，该类主要作用是针对JAR文件进行高效压缩，该类的实现是根据Java类特有的结构——合并常量池、去掉误用信息、保存内联数据结构、使用变量长度编码、选择优化的代码类型进行二次压缩来实现高效压缩。但是该类是针对Java类进行压缩的，所以对普通文件的压缩和普通压缩软件没有什么两样，但是对于Jar文件却能轻易达到10-40%的压缩率，这在Java应用部署中很有用，尤其针对Java移动应用程序的压缩和解压是尤其不错的做法。其使用主要用于class文件比较多的情况，当jar中包含的非Java类的资源文件比较多的时候，如JPEG或者GIF，使用gzip格式是最好的选择，但是如果Jar包中绝大部分都是class内容的话，使用pack200绝对是首选，因为pack200会针对class的java类进行优化设计，Pack200的压缩和解压缩的速度是很快的，而且压缩率也是惊人的，试试就知道了。Java命令行也提供了相关的命令工具：pack200
　　先提供简单的代码段，再示例其操作：
　　压缩：
Pack200.Packer packer = Pack200.newPacker();
OutputStream output = new BufferedOutputStream(new FileOutputStream(outfileName));
packer.pack(new JarFile(jarFile),output);
output.close();
　　解压：
Pack200.Unpacker unpacker = Pack200.newUnpacker();
OutputStream output = new JarOutputStream(new FileOutputStream(jarFile));
unpacker.unpack(pack200File,output);
output.close();
　　——[$]Pack200类例子——
package org.susan.java.io;


import java.io.File;
import java.io.FileOutputStream;
import java.io.OutputStream;
import java.util.jar.JarFile;
import java.util.jar.Pack200;


public class Pack200Tester {
    public static void main(String args[]) throws Exception{
        JarFile file = new JarFile("D:/work/study.jar");
        Pack200.Packer packer = Pack200.newPacker();
        OutputStream out = new FileOutputStream("D:/work/study.pack");
        packer.pack(file, out);
        out.close();
        File inputFile = new File("D:/work/study.jar");
        File outputFile = new File("D:/work/study.pack");
        System.out.println("Before Pack Size: " + inputFile.length());
        System.out.println("After Pack Size: " + outputFile.length());
    }
}
　　这段程序运行后我这里有这样的输出：
Before Pack Size: 293695
After Pack Size: 130423
　　【需要说明的就是：如果JAR本身是一个可执行的JAR，当被Pack200压缩过后，如果要执行的话必须解压才能执行，否则这个JAR文件会直接抛出错误告诉你不能执行，也就是说Pack200针对Jar文件不是单纯的压缩，是进行了高效率的优化，主要目的是为了使得这个Jar在压缩过后体积减小，但是里面的类照样可以引用的，也就是如果是一个java库的话使用这样的方式未尝是一个提供网络jar的比较不错的方式。】
　　——[$]Jar文件列表——
package org.susan.java.io;


import java.io.IOException;
import java.sql.Date;
import java.util.Enumeration;
import java.util.jar.Attributes;
import java.util.jar.JarEntry;
import java.util.jar.JarFile;


public class JarListReader {
    public static void main(String args[]) throws IOException {
        JarFile file = new JarFile("D:/work/study.jar");
        Enumeration&lt;JarEntry&gt; e = file.entries();
        while (e.hasMoreElements()) {
            JarEntry entry = e.nextElement();
            System.out.println(entry.getName());
            long uncompressedSize = entry.getSize();
            long compressedSize = entry.getCompressedSize();
            long crc = entry.getCrc();
            int method = entry.getMethod();
            String comment = entry.getComment();
            System.out.println(new Date(entry.getTime()));
            System.out.println("From " + uncompressedSize + " bytes to " + compressedSize);
            if (method == ZipEntry.STORED) {
                System.out.println("ZipEntry.STORED");
            } else if (method == ZipEntry.DEFLATED) {
                System.out.println(ZipEntry.DEFLATED);
            }
            System.out.println("Its CRC is " + crc);
            System.out.println(comment);
            System.out.println(entry.isDirectory());


            Attributes a = entry.getAttributes();
            if (a != null) {
                Object[] nameValuePairs = a.entrySet().toArray();
                for (int j = 0; j &lt; nameValuePairs.length; j++) {
                    System.out.println(nameValuePairs[j]);
                }
            }
            System.out.println();
        }
    }
}
　　上边这个类会读取Jar文件的清单，这里输出我不一一列举主要是这个文件里面太多内容，仅仅列举其中一部分：
META-INF/MANIFEST.MF
2009-12-19
From 74 bytes to 75
8
Its CRC is 3423671674
null
false


org/susan/java/basic/BreakContinueMain.class
2009-12-18
From 924 bytes to 538
8
Its CRC is 1903539533
null
false
　　但是这样并没有解压，只是一个读取过程，这一点希望读者谨记，如果要解压，直接使用ZIP解压的方式也可以操作。
　　——[$]从一个URL地址获取Jar文件——
package org.susan.java.io;


import java.net.JarURLConnection;
import java.net.URL;
import java.util.jar.JarFile;


public class JarMainEntry {
    public static void main(String args[]) throws Exception{
        //在线地址“ jar:http://hostname/study.jar!/”
        URL url = new URL("jar:file:/D://work//study.jar!/");
        JarURLConnection con = (JarURLConnection)url.openConnection();
        System.out.println(con.getEntryName());
        JarFile jarFile = con.getJarFile();
        //JarEntry entry = con.getJarEntry();
        System.out.println(jarFile.getName());
        //System.out.println(entry.getName());
    }
}
　　这段代码可以直接从一个在线的URL地址获取jar文件，其输出为：
null
D:\work\study.jar
　　在线地址的方式在上边也有说明，这里就不多讲，读者在这里可以举一反三学会使用jar文件的加载，在线读取一个jar文件过后进行jar文件的加载，以及读取jar文件的内容过后找到入口进行程序的运行等！
　　【这里做个简单的小结*：从这里可以知道Jar文件实际上就是一种特殊的Zip文件，里面的内容存在一定的规范而已，而Jar文件和Zip不一样的就在于不仅仅有特殊工具进行二次压缩，而且还可以直接从一个在线地址加载过来进行运行或者载入，而且在线地址的格式是很特殊的，其地址代码里面已经有说明，这里不多讲。】
　　[3]Scanner和Print类
　　Print*类：
　　Java语言里面的输出具有一些特殊的类型：PrintStream和PrintWriter，这里先提供几个简单的例子演示Print*类的用法：【*：Print*类只有Java的输出类里面有，输入类里面不存在这个类型。】
　　PrintStream类是过滤器类中一个不可忽视的成员，最基本的标准输出就要借助于它——我们常用的System.out变量就是PrintStream实例。与之对应的字符流类是PrintWriter类。 
　　PrintStream有两个构造函数(在新版API中已标记为过时)： 
　　public PrintStream(OutputStream out) 
　　public PrintStream(OutputStream out,boolean autoFlush) 
其中，autoFlush置为true时，每当输出遇到换行符，缓冲区的内容就被强制全部输出，如同调用了一次flush()。但要注意，如果没遇到换行符，还是会有数据“憋”在缓冲区里。 
　　方法(已熟悉的就不解释)： 
　　public void write(int b) 
　　public void write(byte b,int offset,int length) 
　　public void flush() 
　　public void close() 
　　public void print(Object obj)
　　这个方法功能是 非常强大的，它可以输出任何对象，而不必另加说明。此外print()方法有许多重载形式，即有多种参数。它们是字符串(String)、字符数组 (char[])、字符(char)、整数(int)、长整数(long)、浮点数(float)、双精度浮点数(double)、布尔值 (boolean)。其中，输出多个数单位的print()方法(也就是指参数为String和char[]的)是同步(synchronized)方 法。 
　　public void println()输出一个换行符。 
　　public synchronized void println(Object obj) 
　　println()方法有9个重载形式，几乎就是print()方法的翻版。唯一的区别在于println()方法都是同步的。 
　　public boolean checkError() 
　　检查输出过程中有什么错误，如有，返回true值。只要输出流中出现一次错误，则出错后的任意对checkError()的调用均会返回真值。
　　——[$]创建PrintWriter和使用——
package org.susan.java.io;


import java.io.PrintWriter;


public class PrintWriterDemo {
    public static void main(String args[]) throws Exception{
        // System.out是一个特殊的OutputStream
        PrintWriter writer = new PrintWriter(System.out);
        // 一些方法举例
        writer.println(true);
        writer.println('A');
        writer.println(500);
        writer.println(40000L);
        writer.println(45.67f);
        writer.println(45.67);
        writer.println("Hello");
        writer.println(new Integer("99"));
        // 关闭PrintWriter
        writer.close();
    }
}
　　这段程序的输出为：
true
A
500
40000
45.67
45.67
Hello
99
　　另外一种创建方式可以通过下边这段代码来实现：
// 从BufferedWriter创建PrintWriter
FileWriter fileWriter = new FileWriter(args[0]);
BufferedWriter bWriter = new BufferedWriter(fileWriter);
PrintWriter pWriter = new PrintWriter(bWriter);
　　PrintStream使用的三个弊端：
　　第一个问题是println的输出是与平台有关的，所以写入控制台不会产生任何的问题。但是对于网络客户端和服务器而言就会出现大的问题！大多数网络协议，如Http和Gnutela，指明换行应当为。所以使用println能编写出能正常工作的windows下的程序但是不能工作在Unix和Mac下，在加上readLine()中本身的bug，如果让带有prinln()的程序会使得服务器和客户端都挂起。 
　　第二个问题是，如果PrintSteam使用的是所在平台使用的默认编码方式。但是，乐中编码方式并不是服务期或客户端所期望的。例如一个接收XML文件的WEB希望以UTF-8或UTF16编码，但是一个使用PrintStream的WEB服务器可能在中国——本地化环境系统上发送GBK或GB2312的编码的文件，而不管客户端是否期望或理解这些方式。那么出现可能出现编码失败或者挂起。 
　　第三个问题是PrintStraem吞掉所有的异常。这就是得PrintStream很适合作为教科书程序，如HelloWorld为了讲受简单的控制台输出，不让学生去理解复杂的异常处理。但是在WEB程序中往往会出现连接中断、带宽提供商的错误、远程系统崩溃和其他不可预知得原因而断开。所以网络程序必须具备处理数据流中意料之外的中断。完成这一点的方法是处理异常。但是PrintStream捕获了低层输出流抛出的所有异常。并且在PrintStream中5个标准的方法并没有throws IOException()的声明： 
public abstract void write(); 
public void write(byte[] data); 
public void write(byte[] data,int offset,int length); 
public void flush(); 
public void close(); 
　　作为替代PrintStream要依靠一个过时标志。如果在底层出现异常，就会设置这个标志，并且程序员要通过checkError()方法检查此标志的值：public boolean checkError()；简单地说printStream提供的错误通知对于不可靠的网络连接而言，是不完全的。
　　Scanner类的使用：
　　Scanner类是JDK 1.5才出来的一个新的类，以前编程的时候，学过C++的人很多人都说Java里面缺乏像C++一样直接从控制台录入的cin类似的操作，而Scanner的改进就可以使得Java也可以完成了，不过Scanner的最初设计目的铁定不仅仅只是为了这么简单的原因的！这个类是Java 5的新特性，主要是简化文本扫描，这个类最实用的地方表现在获取控制台输入，其他的功能相对使用范围比较少，尽管Java API里面针对这个类有大量的方法，但是都不怎么常用。Scanner里面比较实用的几个方法：
public Pattern delimiter()：
返回该Scanner当前正在用于匹配分隔符的Pattern
public Scanner useDelimiter(Pattern pattern)：
将此扫描器的分隔模式设置为指定模式
public Scanner useDelimiter(String pattern)：
将此扫描器的分隔模式设置为从指定 String 构造的模式
public boolean hasNext() throws IllegalStateException：
如果此扫描器的输入中有另一个标记，则返回 true。在等待要扫描的输入时，此方法可能阻塞。扫描器将不执行任何输入。
public boolean hasNextLine() throws IllegalStateException：
如果在此扫描器的输入中存在另一行，则返回 true。在等待输入信息时，此方法可能阻塞。扫描器不执行任何输入。
public String nextLine() throws NoSuchElementException,IllegalStateException：
此扫描器执行当前行，并返回跳过的输入信息。 此方法返回当前行的其余部分，不包括结尾处的行分隔符。当前位置移至下一行的行首。因为此方法会继续在输入信息中查找行分隔符，所以如果没有行分隔符，它可能会缓冲所有输入信息，并查找要跳过的行。
public String next() throws NoSuchElementException：
查找并返回来自此扫描器的下一个完整标记。完整标记的前后是与分隔模式匹配的输入信息。即使以前调用 hasNext() 返回了 true，在等待要扫描的输入时此方法也可能阻塞。
　　——[$]扫描控制台输入——
package org.susan.java.io;


import java.util.Scanner;


public class ScannerDemo {
    public static void main(String args[]){
        Scanner scanner = new Scanner(System.in);
        System.out.println("Please input the string:");
        while(true){
            String line = scanner.nextLine();
            if(line.equals("exit"))
                break;
            System.out.println("&gt;&gt;&gt;" + line);
        }
    }
}
　　上边这段代码的输出为【可交互的控制台】：
Please input the string:
LangYu
&gt;&gt;&gt;LangYu
HelloWorld
&gt;&gt;&gt;HelloWorld
exit
　　*：这里的LangYu、HelloWorld和exit都是用户从控制台输入的字符串，这里就演示了用户从控制台和应用程序交互的过程。
　　——[$]使用Scanner分隔——
package org.susan.java.io;


import java.util.Scanner;


public class ScannerDevide {
    public static void main(String args[]){
        Scanner scanner = new Scanner("123 asdf sd 45 789 sdf asdfl,sdf.sdf,asdf ....asdf las");
        scanner.useDelimiter(" ");
        while(scanner.hasNext()){
            System.out.println(scanner.next());
        }
    }
}
　　该程序的输出为：
123
asdf
sd
45
789
sdf
asdfl,sdf.sdf,asdf
....asdf
las
　　*：上边这段程序注意useDelimiter方法的传入参数，这里的参数应该是一个正则表达式，正则表达式的内容这里不再说明，没有看过前边章节的读者可以参考一下前边正则表达式一章节的内容以参考，这里传入的匹配模式是一个空白符号，所以以空白作为分隔符直接把传入Scanner的字符串进行了分隔并且分开输出。
　　——[$]逐行读取——
package org.susan.java.io;


import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.InputStream;
import java.util.Scanner;


public class SingleLineScanner {
    public static void main(String args[]) throws FileNotFoundException{
        InputStream in = new FileInputStream("D:/work/AutoSubmit.java");
        Scanner scanner = new Scanner(in);
        int number = 1;
        while(scanner.hasNextLine()){
            System.out.print(number + ".  ");
            System.out.println(scanner.nextLine());
            number++;
        }
    }
}
　　这段代码的输出为：
1.  package org.susan.java.io;
2.  
3.  import java.io.BufferedReader;
4.  import java.io.FileReader;
5.  import java.io.FileWriter;
6.  
7.  public class AutoSubmit{
8.   public static void main(String args[]) throws Exception{
9.   FileReader inReader = new FileReader("D:/read.txt");
10.   FileWriter outWriter = new FileWriter("D:/write.txt");
11.   BufferedReader in = new BufferedReader(inReader);
12.   //BufferedWriter out = new BufferedWriter(outWriter);
13.   int c = 0;
14.   while((c = in.read()) != -1){
15.   outWriter.write(c);
16.   }
17.   in.close();
18.   outWriter.close();
19.   }
20.  }
　　这里可以看出这段代码给这段代码每一行添加了行号的输出，主要在于下边这两句话：
System.out.print(number + ".  ");
System.out.println(scanner.nextLine());
　　而且这里可以看出这些代码就是逐行读取的内容。【*：到这里关于Scanner的内容就大致讲解到这个地方，】
　　[4]花1K内存实现高效IO的RandomAccessFile类【摘录自IBM开发中心，这里引入这篇文章是激发读者去思考，因为这篇文章很古老，是02年的文章，实际上JDK 1.4过后完全可以使用下边将会讲到的高级操作。】：
　　这里再谈谈Java的文件随机存取类，RandomAccessFile类的IO效率本身比较低下，这里提供一种解决方案展示如何创建具备缓存读写能力的文件随机存取类，并且进行了优化。一般情况下当开发人员需要文件随机存取的时候，就需要使用RandomAccessFile类，其IO性能较之其他常用开发语言的同类性能差距甚远，严重影响程序的运行效率，这里提供一个测试结果：逐字节拷贝一个12M的文件（这里涉及读写两个操作）。
读 写 时间（秒） 
RandomAccessFile RandomAccessFile 95.829 
BufferedInputStream + DataInputStream BufferedOutputStream + DataOutputStream 2.935 

　　从这里可以看到两者差距约32倍，RandomAccessFile的读写也太慢了点，但是从这个测试确实可以知道Buffered IO的流式读写一个字节，若要操作的数据在BUF中，就直接对内存的buf[]进行读写操作；否则从磁盘响应填充buf[]，再直接对内存的buf[]进行读写操作，绝大部分的读写操作是对内存buf[]的操作。其实：内存存取时间单位是纳秒级（10E-9），磁盘存取时间是毫秒级（10E-3），同样操作一次的开销，内存比磁盘快了百万倍。理论上可以遇见，即使对内存操作上万次，花费的时间也远少于对磁盘一次IO的开销，显然后者是通过增加位于内存的BUF读取，减少磁盘IO的开销，提高存取效率的，当然这样也增加了BUF控制部分的开销，从实际应用看来，效率提高了32倍。
　　根据上边的结论，针对RandomAccessFile的类加上缓冲读写机制，随机访问类与顺序类不同，前者是通过实现DataInput/DataOutput接口创建的，而后者是扩展FilterInputStream/FilterOutputStream创建的，不能直接照搬。
　　其步骤如下：
——开辟缓冲区BUF，默认1024字节，用作读写的公用缓冲区
——先实现读缓冲
　　读缓冲逻辑的基本原理：A欲读文件POS位置的一个字节；B查BUF中是否存在？若有，直接从BUF中读取，并返回该字符byte；C若没有，则BUF重新定位到该POS所在的位置并把该位置附近的BUFSIZE的字节的文件内容填充BUFFER，返回B操作。
　　——[$]实现代码——
package org.susan.java.io;


import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.RandomAccessFile;


public class BufferedRandomAccessFile extends RandomAccessFile{
    // BUF映射在当前文件首的偏移地址
    private long bufstartpos;
    // BUF映射在当前文件尾的偏移地址
    private long bufendpos;
    // 当前类文件指针的便宜地址
    private long curpos = 0;
    // 当改值为真的时候，把buf[]中尚未写入磁盘的数据写入磁盘
    private boolean bufdirty;
    // 已经使用的字节
    private int bufusedsize;
    // 指示当前文件的尾偏移地址，主要考虑到追加因素
    private long fileendpos;
    // 缓冲区字节长度
    private long bufbitlen;
    // 缓冲区字节大小
    private long bufsize;
    // 设置的需要的缓冲区
    private byte[] buf;
    public BufferedRandomAccessFile(String name,String mode) throws FileNotFoundException{
        super(name, mode);
    }
    /**
    * 读取当前文件POS位置所在的字节
    * @param pos
    * @return
    * @throws IOException
    */
    public byte read(long pos) throws IOException{
        if( pos &lt; this.bufstartpos || pos &gt; this.bufendpos){
            this.flushbuf();
            this.seek(pos);
            if(( pos &lt; this.bufstartpos) || (pos &gt; this.bufendpos))
                throw new IOException();
        }
        this.curpos = pos;
        return this.buf[(int)(pos - this.bufstartpos)];
    }
    /**
    * 刷新缓冲区
    * @throws IOException
    */
    private void flushbuf() throws IOException{
        if( this.bufdirty == true){
            if( super.getFilePointer() != this.bufstartpos){
                super.seek(this.bufstartpos);
            }
            super.write(this.buf,0,this.bufusedsize);
            this.bufdirty = false;
        }
    }
    /**
    * 移动指针到pos位置，并且把buf[]映射填充到POS所在的文件块
    */
    public void seek(long pos) throws IOException{
        if((pos &lt; this.bufstartpos) || ( pos &gt; this.bufendpos)){
            this.flushbuf();
            if((pos &gt;= 0 ) &amp;&amp; (pos &lt;= this.fileendpos) &amp;&amp; (this.fileendpos != 0)){
                this.bufstartpos = pos * this.bufbitlen / this.bufbitlen;
                this.bufusedsize = this.fillbuf();
            }else if(( pos == 0 ) &amp;&amp; ( this.fileendpos == 0) || (pos == this.fileendpos + 1)){
                this.bufstartpos = pos;
                this.bufusedsize = 0;
            }
            this.bufendpos = this.bufstartpos + this.bufsize -1;
        }
        this.curpos = pos;
    }
    /**
    * 根据bufstartpos，填充buf[]
    * @return
    * @throws IOException
    */
    private int fillbuf() throws IOException{
        super.seek(this.bufstartpos);
        this.bufdirty = false;
        return super.read(this.buf);
    }
}
　　这样缓冲读取就已经实现了，用这种方式测试一下读写速度，就可以发现【这里同样读取12M的文件】：
读 写 时间（秒） 
BufferedRandomAccessFile BufferedOutputStream + DataOutputStream 2.833 

　　从这里的测试可以看出，BufferedRandomAccessFile的读取速度和BufferedInputStream + DataInputStream不相上下
——接下来实现缓冲写
　　缓冲写的基本原理：A欲写文件POS位置的一个字节；B查BUF中是否有该映射？若有，直接向BUF中写入，并返回true；C若没有，则BUF重新定位到POS所在的位置，并把该位置附近的BUFSIZE字节的文件内容填充到BUFFER，返回B步骤
　　这里提供关键代码，在上边类里面添加下边的方法来实现：
/**
* 根据POS的不同以及BUF的位置：存在修改、追加、BUF中、BUF外等情况。
* 在逻辑判断时，把最可能出现的情况，最先判断可以提高速度
* @param bw
* @param pos
* @return
* @throws IOException
*/
public boolean write(byte bw, long pos) throws IOException {
    if ((pos &gt;= this.bufstartpos) &amp;&amp; (pos &lt;= this.bufendpos)) {
        this.buf[(int) (pos - this.bufstartpos)] = bw;
        this.bufdirty = true;
        if (pos == this.fileendpos + 1) {
            this.fileendpos++;
            this.bufusedsize++;
        }
    } else {
        this.seek(pos);
        if ((pos &gt;= 0) &amp;&amp; (pos &lt;= this.fileendpos) &amp;&amp; (this.fileendpos != 0)) {
            this.buf[(int) (pos - this.bufstartpos)] = bw;
        } else if (((pos == 0) &amp;&amp; (this.fileendpos == 0)) || (pos == this.fileendpos + 1)) {
            this.buf[0] = bw;
            this.fileendpos++;
            this.bufusedsize = 1;
        } else {
            throw new IndexOutOfBoundsException();
        }
        this.bufdirty = true;
    }
    this.curpos = pos;
    return true;
}
　　上边这个方法就实现了缓冲写操作，再测试一下：
读 写 时间（秒） 
BufferedRandomAccessFile BufferedRandomAccessFile 2.453 

　　可见综合速度已经有所提升了
——优化BufferedRandomAccessFile
　　优化原理：A调用频繁的语句最需要优化，且优化效果比较明显；B多重嵌套逻辑判断时，最可能出现的判断应放在最外层；C减少不必要的NEW操作，比如seek方法。
　　优化过后再测试可以看到测试结果：
读 写 时间（秒） 
BufferedRandomAccessFile优 BufferedRandomAccessFile优 2.197 

　　虽然看起来优化不是很明显，但是比未优化前快了一点点，这种效果在以前的机器上可能更加明显，以上比较的是顺序存取，即使是随机存取，绝大部分情况不止一个BYTE，所以缓冲机制很有效的。其实这里的优化就在于seek方法内部的代码设置，使用的是位移运算和直接偏移量的运算来完善的。
——整体完善：
　　提供文件追加功能，添加方法：
public boolean append(byte bw) throws IOException{
    return this.write(bw, this.fileendpos + 1);
}
　　提供文件当前位置修改功能：
public boolean write(byte bw) throws IOException{
    return this.write(bw,this.curpos);
}
　　返回文件长度，因为提供了BUF读写的原因，与原来的类有所不同：
public long length() throws IOException{
    return this.max(this.fileendpos + 1, this.initfilelen);
}
　　返回当前指针：
public long getFilePointer() throws IOException{
    return this.curpos;
}
　　完善过程中这里还有两个重要方法就是缓冲读写方法的改写：
　　提供对当前位置的多个字节的缓冲写功能：
public void write(byte b[], int off, int len) throws IOException {
    long writeendpos = this.curpos + len - 1;
    if (writeendpos &lt;= this.bufendpos) { 
        System.arraycopy(b, off, this.buf,
            (int) (this.curpos - this.bufstartpos), len);
        this.bufdirty = true;
        this.bufusedsize = (int) (writeendpos - this.bufstartpos + 1);
    } else { 
        super.seek(this.curpos);
        super.write(b, off, len);
    }
    if (writeendpos &gt; this.fileendpos)
        this.fileendpos = writeendpos;
    this.seek(writeendpos + 1);
}
　　提供对当前位置的多个字节的缓冲读功能：
public int read(byte b[], int off, int len) throws IOException {
    long readendpos = this.curpos + len - 1;
    if (readendpos &lt;= this.bufendpos &amp;&amp; readendpos &lt;= this.fileendpos) {
        System.arraycopy(this.buf, (int) (this.curpos - this.bufstartpos),b, off, len);
    } else {
        if (readendpos &gt; this.fileendpos) {
            len = (int) (this.length() - this.curpos + 1);
        }
        super.seek(this.curpos);
        len = super.read(b, off, len);
        readendpos = this.curpos + len - 1;
    }
    this.seek(readendpos + 1);
    return len;
}


public int read(byte b[]) throws IOException {
    return this.read(b, 0, b.length);
}


public void setLength(long newLength) throws IOException {
    if (newLength &gt; 0) {
        this.fileendpos = newLength - 1;
    } else {
        this.fileendpos = 0;
    }
    super.setLength(newLength);
}


public void close() throws IOException {
    this.flushbuf();
    super.close();
}
　　最后提供一个测试的总表来完成几种不同方法之间的对比：
读 写 时间（秒） 
RandomAccessFile RandomAccessFile 95.829 
BufferedInputStream + DataInputStream BufferedOutputStream + DataOutputStream 2.935 
BufferedRandomAccessFile BufferedOutputStream + DataOutputStream 2.833 
BufferedRandomAccessFile BufferedRandomAccessFile 2.453 
BufferedRandomAccessFile优 BufferedRandomAccessFile优 2.197 
BufferedRandomAccessFile完 BufferedRandomAccessFile完 0.401 

　　【*：从这里可以看出，进行了整体优化过后效率已经提高了不少，但是这个是在JDK 1.3的时候常用的优化方法，JDK1.4过后提供了java.nio包，其性能和整体优化过后的性能不相上下，提供这篇文章的主要目的是为了使读者能够深入思考这些代码的为什么，IBM测试中心已经针对这些内容进行了严格测试，这里的测试结果不是一台机器跑出来的结果。通过这样的优化和思考就明白如何进行IO的优化，当然常用的手段是使用缓冲区，这里也可以看出来，关于java.nio下边章节进行讲解，使用java.nio的读写上边同样的例子估计1.2秒左右。这些内容我在机器上尝试了读写一个40M左右的文件，测试结果基本一样，但是使用的JDK是1.4以下的。】


3.文件高级操作
　　JDK 1.4介绍了许多提高IO性能的过程，这里有一种IO称为“新的IO”，主要是使用了java.nio包，这个包提供了下边几种功能：
设置字符编码的编码器（encoder）和解码器（decoder） 
非阻塞IO 
内存映射文件 
文件锁 
　　使用java.nio的功能的性能优势在于：
能够直接从硬盘上、而不需要一字节一字节地读写数据块，当你在非阅读期间将数据从缓冲器中提出时，它处理低字节优先问题。 
可以进行非阻塞异步输入/输出 
你能够锁定整个或部分文件 
　　那么NIO的原理是什么呢？Java NIO的一些应用通常适用在IO读写方面，我们知道系统运行的性能瓶颈通常在IO读写，包括对端口和文件的操作，过去打开一个IO通道过后，通过读取一直等待在一个端口读取一个字节内容，如果没有字节内容进来，则应用程序的读取操作也是傻傻等待，这样就影响了程序继续做其他的事情，而改进方法就是开设线程让线程来等待，实际上通过实践可以知道这样的方法同样也是非常耗时的。Java NIO非堵塞技术实际是采取Reactor模式，或者说是Observer模式为我们监察I/O端口，如果有内容进来，会自动通知我们，这样，我们就不必开启多个线程死等，从外界看，实现了流畅的I/O读写，不堵塞了。Java NIO出现不只是一个技术性能的提高，你会发现网络上到处在介绍它，因为它具有里程碑意义，从JDK1.4开始，Java开始提高性能相关的功能，从而使得Java在底层或者并行分布式计算等操作上已经可以和C或Perl等语言并驾齐驱。如果你至今还是在怀疑Java的性能，说明你的思想和观念已经完全落伍了，Java一两年就应该用新的名词来定义。从JDK1.5开始又要提供关于线程、并发等新性能的支持，Java应用在游戏等适时领域方面的机会已经成熟，Java在稳定自己中间件地位后，开始蚕食传统C的领域。【*：此段摘录自http://www.jdon.com/concurrent/nio%D4%AD%C0%ED%D3%A6%D3%C3.htm】
　　Java的NIO包里面引入了四个关键的抽象数据类型，它们相互配合共同解决了传统的IO中一些问题。
Buffer：它是包含数据并且用于读写的线性表结构，其中提供了一些特殊类用的内存映射文件的IO操作 
Charset：它提供了Unicode字符串影射到字节序列以及逆影射的操作 
Channels：包含了socket、file和pipe三种通道，实际上是双向交流的通道。 
Selector：它将多元异步IO操作几种到一个或者多个线程中 
　　Java的NIO包里面引入了一种称为通道的新型原始输入输出提取方法，通道表示实体（硬件设备、文件、网络套接字或者可以执行一个或者多个独特的注入读和写之类的输入输出操作的程序组件）的开放连接，操作的一个线程可以被阻止，而另外一个线程能够关闭通道，这是通道的一个突出的特点，当通道关闭的时候，被阻止的线程用一个异常激活，表明通道是被关闭的。
　　i.基本术语：
　　内存映射文件：
　　内存映射文件的IO市一中读写数据的方法，它可以比常规的基于流或者基于通道的IO高效很多，内存映射文件IO的读写方式是通过使用文件中的数据组合成为内存数组的内容来完成的，咋一听貌似这种方式是将整个文件读取到整个内存中，实际上不是的，在读写过程中只有真正在读写的部分才会进入内存，这种方式称为映射。现在很多操作系统一般都会根据需要将文件或者文件中的某些部分映射为内存的一部分内容，从而实现文件系统，Java内存映射机制不过使用的是针对底层操作系统的该机制的一种使用。
　　缓冲区结构：
　　当我们在使用内存映射的时候，需要将让一个内存里面单独的缓冲区和一个实体文件或者一个实体文件的域进行交互，在这样的情况下就需要提供一个缓冲区的简单的数据结构。缓冲区的结构如下：

　　从上边的图可以知道，一个缓冲区包含下边几个部分：
一个绝对不会改变的缓冲区的容量capacity 
下一个值的读写位置position 
无意义读写的一个限制空间limit 
额外的还有一个用来重复读写的标记mark 
　　文件锁（File Locking）：
　　文件锁是JDK1.4引入的一种机制，它允许我们同步访问某个作为共享资源的文件，竞争同一个文件的两个线程可能在不同的Java虚拟机上边，或者一个是Java线程，另外一个是操作系统中的某个系统线程，文件锁对其他的操作系统进程是可见的，因为Java的文件加锁直接映射到了本地操作系统的加锁工具。一般情况下使用FileChannel的方法tryLock()或lock()方法就可以获得文件的FileLock，tryLock()方法是非阻塞方式的，它设法获取锁，但是如果不能获得的话，它将直接从方法调用返回，lock()则是阻塞方式，它要阻塞进程知道锁可以获得，或调用lock()的线程中断或者调用lock()的关闭。对独占锁和共享锁的支持必须由底层的操作系统提供。锁的类型可以通过FileLock.isShared()进行查询。另外，我们不能获取缓冲器上的锁，只能是通道上的。文件加锁的实际应用之一：文件映射通常应用于大型的文件，我们可能需要对巨大的文件进行部分加锁，以便其他的进程可以修改文件中未被加锁的部分，数据库就是如此，使得多用户可以访问到未加锁的部分数据。其他的应用还知之甚少。
　　ii.NIO初探【诱导初学者教程】：
　　Java NIO里面一个主要的类是Selector，这个类似一个观察者，只要在写程序过程把需要探知的socketchannel告诉Selector，我们就可以直接做其他的事情，当有事件发生的时候，他会通知我们，传回一个SelectionKey，读取这些Key就可以获取刚刚注册过的SocketChannel，然后就可以从这个Channel中读取锁需要的数据，它保证我们在读写过程能够读取到这些数据，接着还可以针对这些数据进行处理。Selector内部原理其实很简单，就是针对一个注册过的Channel进行轮询访问，不断的轮询一旦轮询到一个Channel有所注册的事情发生，比如数据来了等就会发送报告，交出一个Key，让程序通过该Key直接读取这个Channel的内容。
　　【*：关于Java NIO我们在编程过程可以这样理解，实际上Java NIO的大部分内容都不是Java语言本身实现的，它之所以效率比较高是因为它本身使用的就是操作系统底层的IO部分的API而不是基于JVM级别的，而它的实现语言使用的是C，所以它在读写过程和操作系统紧密相关，而利用上边讲解的原理就可以完整实现Java的高效读取，这种方式和我们前边遇到的Java IO的方式有本质上的区别，而如何使用Java书写接口而换用C语言书写实现读者可以参考JNI的有关文档。】
　　接下来提供几个例子来说明Java NIO的API的相关用法：
　　——[$]使用映射文件来读取文本文件——
package org.susan.java.io;


import java.io.FileInputStream;
import java.io.IOException;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;


public class NativeMapFile {
    public static void main(String args[]){
        FileInputStream fileInputStream;
        FileChannel fileChannel;
        long fileSize;
        MappedByteBuffer mBuffer;
        try{
            fileInputStream = new FileInputStream("D:/work/test.txt");
            fileChannel = fileInputStream.getChannel();
            fileSize = fileChannel.size();
            mBuffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, 0, fileSize);
            for( int i = 0; i &lt; fileSize; i++ ){
                System.out.print((char)mBuffer.get());
            }
            fileChannel.close();
            fileInputStream.close();
        }catch(IOException ex){
            ex.printStackTrace();
        }
    }    
}
　　上边这段代码会使用本地映射文件读取某个文件里面的内容，test.txt里面的内容为：
你好么？你好啊！
HelloWorld!
　　以下是该程序的输出结果：
￯ﾻ﾿￤ﾽﾠ￥ﾥﾽ￤ﾹﾈ￯ﾼﾟ￤ﾽﾠ￥ﾥﾽ￥ﾕﾊ￯ﾼﾁ
HelloWorld!
　　可以知道一点就是直接使用这种方式读取文件，有可能会出现中文的乱码问题，不过这个问题稍候想办法解决，这里先介绍几个NIO里面的几个重要知识点：FileChannel.MapMode是文件影射模型的安全的枚举，主要有几个值：
FileChannel.MapMode.PRIVATE：专用（写入时拷贝）映射模式
FileChannel.MapMode.READ_ONLY：只读映射模式
FileChannel.MapMode.READ_WRITE：读取、写入映射模式
　　其实java.nio里面的一个核心类就是上边使用到的FileChannel，该类的介绍如下：
　　定义：
public abstract class FileChannel extends AbstractInterruptibleChannel implements ByteChannel, GatheringByteChannel, ScatteringByteChannel
　　该类是用于读取、写入、映射和操作文件的通道，文件通道在文件内部有一个当前的position，可以对其进行查询和修改，该文件本身包含一个可读写的长度的可变字节序列，并且可以通过查询该文件的当前大小，写入字节超出文件的当前大小时，则增加文件的大小；截取该文件的时候，则减小文件的大小，文件可能还有某个相关联的元数据，如访问权限、内容类型和最后的修改时间，该类却没有定义元数据的方法。除了字节通道中常见的读取、写入和关闭操作，此类还定义了下列特定于文件的操作：
以不影响通道当前位置的方式，对文件中绝对位置的字节进行读取和写入 
将文件中的某个区域直接映射到内容中，对于较大的文件，这通常比调用普通的read或write方式更加高效 
强制对底层存储设备进行文件更新，以确保在系统崩溃的时候不丢失数据 
以一种可以被很多操作系统优化为直接向文件系统缓存发送或从中读取的高速传输方法，将字节从文件传输到某个其他通道中，反之亦然 
可以锁定某个文件区域，以阻止其他程序进行访问 
　　多个并发线程可安全地使用文件通道，可随时调用关闭方法，正如Channel接口中所指定，对于涉及通道位置或者可以更改文件大小的操作，在任意给定时间只能进行一个这样的操作，如果尝试在第一操作仍在进行时发起第二个操作，则会导致在第一个操作完成之前阻塞第二个操作。可以并发处理其他操作，特别是采用显示位置的操作，但是否并发处理则取决于系统，因此是未指定的。确保此类的实例所提供的文件视图与同一程序中其他实例所提供的相同文件视图是一致的。但是，此类的实例所提供的视图不一定与其他并发运行的程序所看到的视图一致，这取决于底层操作系统所执行的缓冲策略和各种网络文件系统协议所引入的延迟。不管其他程序是以何种语言编写的，而且也不管是运行在相同机器还是不同机器上都是如此。此种不一致的确切性质取决于系统，因此是未指定的。此类没有定义打开现有文件或创建新文件的方法，以后的版本中可能添加这些方法。在此版本中，可从现有的 FileInputStream、FileOutputStream 或 RandomAccessFile 对象获得文件通道，方法是调用该对象的 getChannel 方法，这会返回一个连接到相同底层文件的文件通道。文件通道的状态与其 getChannel 返回该通道的对象密切相关。显式或者通过读取或写入字节来更改通道的位置将更改发起对象的文件位置，反之亦然。通过文件通道更改此文件的长度将更改通过发起对象看到的长度，反之亦然。通过写入字节更改此文件的内容将更改发起对象所看到的内容，反之亦然。此类在各种情况下指定要求“允许读取操作”、“允许写入操作”或“允许读取和写入操作”的某个实例。通过 FileInputStream 实例的 getChannel 方法所获得的通道将允许进行读取操作。通过 FileOutputStream 实例的 getChannel 方法所获得的通道将允许进行写入操作。最后，如果使用模式 "r" 创建 RandomAccessFile 实例，则通过该实例的 getChannel 方法所获得的通道将允许进行读取操作，如果使用模式 "rw" 创建实例，则获得的通道将允许进行读取和写入操作。如果从文件输出流中获得了允许进行写入操作的文件通道，并且该输出流是通过调用 FileOutputStream(File,boolean) 构造方法且为第二个参数传入 true 来创建的，则该文件通道可能处于添加模式。在此模式中，每次调用相关的写入操作都会首先将位置移到文件的末尾，然后再写入请求的数据。在单个原子操作中是否移动位置和写入数据是与系统相关的，因此是未指定的。 
　　【思考*：使用FileChannel的时候主要是针对字节序列进行操作，那么和前面提及到的Java普通IO交互的部分大部分都是字节流读写器，参考字节流读写器中间可以发现一部分Stream类型的读写器可以通过getChannel方法获取文件通道。】
　　下边再引入一个FileChannel的例子：
　　——[$]写入文件，使用新的IO——
package org.susan.java.io;


import java.io.FileOutputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;


public class NativeFileWrite {
    public static void main(String args[]){
        FileOutputStream fileOutputStream;
        FileChannel fileChannel;
        ByteBuffer byteBuffer;
        try{
            fileOutputStream = new FileOutputStream("D:/work/test.txt");
            fileChannel = fileOutputStream.getChannel();
            byteBuffer = ByteBuffer.allocateDirect(26);
            for( int i = 0; i &lt; 26; i++ )
                byteBuffer.put((byte)('A' + i));
            byteBuffer.rewind();
            fileChannel.write(byteBuffer);
            fileChannel.close();
            fileOutputStream.close();
        }catch(IOException ex){
            ex.printStackTrace();
        }
    }
}
　　该例子演示了向一个文件内写入英文字母A到Z的全过程，下边是写入过后test.txt里面的文件内容：
ABCDEFGHIJKLMNOPQRSTUVWXYZ
　　这里再介绍一个类：ByteBuffer类，该类针对字节进行了六种操作：
读写单个字节的绝对和相对get和put方法 
将此缓冲区的连续字节列传输到数组中的相对批量get方法 
将byte数组或其他字节缓冲区中的连续字节序列传输到此缓冲区的相对批量put方法 
读写其他基本类型值，并按照特定的字节序列在字节序列之间转换这些值的get和put方法 
创建视图缓冲区的方法，这些方法允许将字节缓冲区视为包含其他基本类型值的缓冲区 
对字节缓冲区进行compacting、duplicating和slicing的方法 
　　直接与非直接缓冲区：
　　ByteBuffer有两个创建缓冲区的方法：
static ByteBuffer allocate(int capacity)
static ByteBuffer allocateDirect(int capacity)
　　这两个方法都是创建缓冲区的方法，使用直接缓冲区的时候，JVM虚拟机会直接在此缓冲区上执行本机IO操作，也就是说，在每次调用基础操作系统的一个本机IO之前或者之后，虚拟机都会避免将缓冲区的内容复制到中间缓冲区（或者从中间缓冲区复制内容）。直接字节缓冲区使用上边方法中的allocateDirect工厂方法创建，此方法返回的缓冲区进行分配和取消分配所需要的成本往往比间接缓冲区要高，直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内容需求量造成的影响可能并不明显，所以建议将直接缓冲区主要分配给那些容易受基础系统的本机IO操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处的时候分配它们。
　　直接缓冲区还可以使用mapping将文件区域直接映射到内存中来创建，Java平台的实现有助于通过JNI从本机代码直接创建字节缓冲区，如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则视图访问该区域不会更改该缓冲区的内容，并且会在访问期间或稍候的某个时间导致抛出不确定的异常。
　　字节缓冲区是直接缓冲区还是非直接缓冲区可以通过ByteBuffer的isDirect方法来确定，提供该方法是为了能够在性能关键型代码中执行显示缓冲区管理。
　　访问二进制数据：
　　此类定义除了boolean之外，读写所有其他基本类型值的方法，这些基本值可以根据缓冲区的当前字节顺序与字节序列相互进行转换，并可以通过order方法获取和修改。特定的字节顺序由ByteOrder类的实例进行表示，字节缓冲区的初始顺序是BIG_ENDIAN（该顺序可以参考《Java内存模型》http://blog.csdn.net/silentbalanceyh/archive/2009/10/13/4661230.aspx）的。为了访问异类二进制数据，此类还针对每种类型定义了一系列绝对和相对的put和get方法，并针对float、char、short、int、long和double等类型定义了相对方法，该方法可以自行参考API内容。绝对get和put方法的index参数是根据字节定义的，而不是根据所读写的类型定义的。
　　为了访问同类二进制数据（即相同类型的值序列），此类还定义了可以为指定类型的缓冲区创建视图的方法，视图缓冲区只是其内容受该字节缓冲区支持的另一种缓冲区，字节缓冲区内容的更改在视图缓冲区中是可见的，反之亦然；这两种缓冲区的位置、限制和标记值都是独立的。使用视图缓冲区有三大优势：
视图缓冲区不是根据字节进行索引，而是根据其特定于类型的值的大小进行索引 
视图缓冲区提供了相对批量put和get方法，这些方法可在缓冲区和数组或相同类型的其他缓冲区之间传输值的连续序列 
视图缓冲区可能更高效，这是因为，当且仅当其支持的字节缓冲区为直接缓冲区时它才是直接缓冲区。 
　　实际上ByteBuffer是继承于Buffer类，里面存放的是字节，如果要将它们转换成字符串则需要使用Charset，Charset是字符编码，它提供了把字节流转换成为字符流（解码）和将字符串转换成字节流（编码）的方法。该类有一下三个重要的属性：
容量（capacity）：表示该缓冲区可以存放多少数据 
极限（limit）：表示读写缓存的位置，不能对超过位置进行数据的读或写操作 
位置（position）：表示下一个缓冲区的读写单元，每读写一次缓存区，位置都会变化，位置是一个非负整数 
　　——[$]快速复制文件——
package org.susan.java.io;


import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;


public class QuickCopy {
    public static void main(String args[]) throws Exception{
        FileInputStream fin = new FileInputStream("D:/work/test.txt");
        FileOutputStream fout = new FileOutputStream("D:/work/output.txt");
        FileChannel inChannel = fin.getChannel();
        FileChannel outChannel = fout.getChannel();
        ByteBuffer buffer = ByteBuffer.allocate(1024);
        while(true){
            int ret = inChannel.read(buffer);
            if( ret == -1)
                break;
            buffer.flip(); //该方法为父类Buffer的方法
            outChannel.write(buffer);
            buffer.clear(); //该方法为父类Buffer的方法
        }
    }
}
　　上边的代码分配了1024个字节的直接缓冲区，然后使用本地拷贝的方式进行文件拷贝，应该是比普通的文件拷贝更高效，这里解释几个比较常用的ByteBuffer类里面的方法【这里不介绍分配缓冲区的方法了】：
public abstract ByteBuffer compact() throws ReadOnlyBufferException：
——该方法压缩此缓冲区（可选的），将缓冲区的当前位置和界限之间的字节复制到缓冲区的开始处，即将索引p = position()处的字节复制到索引0处，将索引n+1处的字节复制到索引1的位置，依次类推直到索引limit() - 1处的字节复制到索引 n = limit() - 1 - p处，然后将缓冲区的位置设置为n + 1，并将其界限设置为其容量，如果已定义了标记，则丢弃。将缓冲区的位置设置为复制的字节数，而不是零，以便调用此方法后可以紧接着调用另一个相对put方法。
public abstract ByteBuffer duplicate()：
——创建共享此缓冲区内容的新的字节缓冲区，新缓冲区的内容将为此缓冲区的内容，此缓冲区内容的更改在新缓冲区中是可见的，反之亦然；这两个缓冲区的位置、界限和标记值是相互独立的。新缓冲区的容量、界限、位置和标记值将与此缓冲区相同。当且仅当此缓冲区为直接时，新缓冲区才是直接的，当切仅当此缓冲区是只读时，新缓冲区才是只读的。
public abstract ByteBuffer slice()：
——创建新的字节缓冲区，其内容是此缓冲区的共享子序列，新缓冲区的内容将从此缓冲区的当前位置开始，此缓冲区内容的更改在新缓冲区中是可见的，反之亦然；这两个缓冲区的位置、界限和标记值是相互独立的。
public abstract ByteBuffer wrap(byte[] array)：
——将byte数组包装到缓冲区中，新的缓冲区将由给定的byte数组支持，也就是说，缓冲区修改将导致数组修改，反之亦然。新缓冲区的容量和界限将为array.length，其位置将为零，其标记是不确定的，其底层实现数据将为给定数组，并且其数组偏移量将为零。
　　这里再提供几个基本操作的例子：
　　——[$]基本类型和ByteBuffer——
package org.susan.java.io;


import java.nio.ByteBuffer;
import java.nio.CharBuffer;


public class BasicType {
    public static void main(String args[]) throws Exception{
        // 使用字节数组创建ByteBuffer
        byte[] bytes = new byte[10];
        ByteBuffer buffer = ByteBuffer.wrap(bytes);
        // 创建字符ByteBuffer
        ByteBuffer charBuffer = ByteBuffer.allocate(15);
        CharBuffer charBuffer2 = buffer.asCharBuffer();
        // 设置获取字符类型的Buffer
        ByteBuffer charBuffer3 = ByteBuffer.allocate(100);
        charBuffer3.putChar((char)123);
        charBuffer3.flip();
        char c = charBuffer3.getChar();
    }
}
　　上边是针对基本类型的操作，查阅API可以看到基本操作相关的类里面提供的方法
　　——[$]String和ByteBuffer——
package org.susan.java.io;


import java.nio.ByteBuffer;
import java.nio.CharBuffer;


public class StringByteBuffer {
    public static void main(String args[]) throws Exception{
        // 使用ByteBuffer存储字符串
        ByteBuffer buffer = ByteBuffer.allocate(100);
        CharBuffer cBuffer = buffer.asCharBuffer();
        cBuffer.put("Hello World");
        cBuffer.flip();
        String result = cBuffer.toString();
    }
}
</content>
<bookmark>10418</bookmark>
</TextBean><TextBean UUID="fb8145fdf84348f8a397660eb5938d95">
<name>AJAX</name>
<content>AJAX = Asynchronous JavaScript and XML.

AJAX = 异步JavaScript和XML

AJAX is based on JavaScript and HTTP requests.

AJAX是基于JavaScript和HTTP请求的。

AJAX is a type of programming made popular in 2005 by Google (with Google Suggest).

AJAX是Google倡导在2005年流行起来的一类编程技术。

AJAX is not a new programming language, but a new way to use existing standards.

AJAX不是一门全新的编程语言，仅仅是现有技术基础的一个新门类。

Start learning AJAX now! 

让我们开始学习AJAX吧

AJAX Introduction
AJAX 简介
  
--------------------------------------------------------------------------------

What you should already know
哪些是您应该已经知晓的
Before you continue you should have a basic understanding of the following:

在我们继续前您应该有这些基础知识：

HTML / XHTML 
JavaScript 
If you want to study these subjects first, find the tutorials on our Home page.

如果你想先学习这些技术，在我们的首页上有这些教程。


--------------------------------------------------------------------------------

AJAX = Asynchronous JavaScript and XML
AJAX = 异步JavaScript和XML
AJAX is not a new programming language, but a new technique for creating better, faster, and more interactive web applications.

AJAX不是一种新的程序语言，但是一种为创建更好，更快，和更多交互性web应用程序的新技术。

With AJAX, a JavaScript can communicate directly with the server, with the XMLHttpRequest object. With this object, a JavaScript can trade data with a web server, without reloading the page.

AJAX中，利用XMLHttpRequest对象，JavaScript可以直接与服务器交互。正是使用了这个对象，JavaScript能从服务器端获取数据而不用重新装载页面。

AJAX uses asynchronous data transfer (HTTP requests) between the browser and the web server, allowing web pages to request small bits of information from the server instead of whole pages.

AJAX在服务器和客户端之间使用异步数据传输（HTTP请求），允许网页从服务器上请求小量的信息而不用服务器发送整个页面。

The AJAX technique makes Internet applications smaller, faster and more user-friendly.

AJAX技术让互联网应用更小，更快和更友善的客户界面。


--------------------------------------------------------------------------------

AJAX is based on Internet standards
AJAX是基于互联网基础技术的
AJAX is based on the following web standards:

AJAX是基于如下的互联网基础技术：

JavaScript 
XML 
HTML 
CSS 
 AJAX applications are browser- and platform-independent.

 （注意）AJAX程序还是有浏览器和操作系统的平台依赖性的。


--------------------------------------------------------------------------------

AJAX is about better Internet-applications
AJAX是更好的网络应用
Internet-applications have many benefits over desktop applications; they can reach a larger audience, they are easier to install and support, and easier to develop.

互联网应用相较于桌面应用还是有很多优点的；它更容易有庞大的用户群，它更容易安装和技术支持，且更容易开发。

However, Internet-applications are not always as "rich" and user-friendly as traditional desktop applications. 

然而互联网应用相较于传统的桌面应用程序不是那么丰富多彩和用户友善度。

With AJAX, Internet applications can be made richer and more user-friendly.

所以AJAX技术弥补了互联网应用的不足，使网络应用更加丰富和更加友善。


--------------------------------------------------------------------------------

Start using AJAX today
让我们今天就开始使用AJAX
There is nothing new to learn.

并不用学习新东西呦^_^。

AJAX is based on existing standards. These standards have been used by developers for several years.

AJAX是基于已经存在的技术标准的。这些基础技术对于开发者来说有的都已经使用好多年了。

Your first AJAX application
您的第一个AJAX应用程序
To understand how AJAX works, we will create a small AJAX application.

我们将创建一个小的AJAX应用程序，以让您明白AJAX是如何工作的。

First we are going to create a standard HTML form with two input fields: Name and Time. The "Name" field will be filled out by the user, and the "Time" field will be filled out with AJAX.

首先我们创建一个基础的HTML表单，它带有两个输入框：姓名和时间。姓名字段将有用户填写，同时时间字段将由AJAX技术自动填写。

The HTML file will be named "testAjax.htm", and it looks like this (notice that the HTML form below has no submit button!):

我们把这个HTML文件命名为：testAjax.htm,它的样式是这样（请注意这个HTML表单没有提交按钮）：

&lt;!--文件名：testAjax.htm--&gt;

&lt;html&gt;
&lt;body&gt;

&lt;form name="myForm"&gt;
Name: &lt;input type="text" name="username" /&gt;
Time: &lt;input type="text" name="time" /&gt;
&lt;/form&gt;

&lt;/body&gt;
&lt;/html&gt;
 

The next chapters will explain the keystones of AJAX.

下一章节我们将解释AJAX技术核心的基石。

AJAX - Browser support
AJAX-浏览器支持
The keystone of AJAX is the XMLHttpRequest object.

AJAX技术的基石是XMLHttpRequest对象。

All new browsers use the built-in JavaScript XMLHttpRequest object to create an XMLHttpRequest object (IE5 and IE6 uses an ActiveXObject).

所有新版的浏览器都可以通过内建的JavaScript XMLHttpRequest 对象来创建一个XMLHttpRequest对象。（IE5和IE6用ActiveXObject对象）

Let's update our "testAjax.htm" file with a JavaScript that creates an XMLHttpRequest object:

让我们更新testAjax.htm文件，文件内用JavaScript去创建一个XMLHttpRequest对象：

&lt;!--更新的testAjax.htm文件--&gt;

&lt;html&gt;
&lt;body&gt;

&lt;script type="text/javascript"&gt;
function ajaxFunction()
{
var xmlhttp;
if (window.XMLHttpRequest)
{ 
// code for IE7+, Firefox, Chrome, Opera, Safari 
//适用于IE7以上版本浏览器，火狐浏览器，Chrome浏览器，Opera浏览器，Safari浏览器

xmlhttp=new XMLHttpRequest(); 
} 
else if (window.ActiveXObject)
{ 
// code for IE6, IE5 
//适用于IE6，IE5
xmlhttp=new ActiveXObject( "Microsoft.XMLHTTP");
} 
else
{ 
alert( "Your browser does not support XMLHTTP!");
} 
}
&lt;/script&gt;

&lt;form name="myForm"&gt;
Name: &lt;input type="text" name="username" /&gt;
Time: &lt;input type="text" name="time" /&gt;
&lt;/form&gt;

&lt;/body&gt;
&lt;/html&gt;
 

Example explained
实例解析
1. Create a variable named xmlhttp to hold the XMLHttpRequest object.

1、创建变量xmlhttp去操控XMLHttpRequest对象。

2. Try to create the XMLHttpRequest object with xmlhttp=new XMLHttpRequest(). 

2、通过xmlhttp=new XMLHttpRequest()实例化XMLHttpRequest对象。

3. If that fails, try xmlhttp=new ActiveXObject("Microsoft.XMLHTTP"). This is for IE6 and IE5.

3、if条件不成立时，xmlhttp=new ActiveXObject("Microsoft.XMLHTTP"),是为了IE6和IE5这样的低版本IE浏览器。

4. If that fails too, the user has a very outdated browser, and will get an alert stating that the browser doesn't support XMLHTTP.

4、if条件仍然不成立时，即用户使用非常老版本的浏览器时，将弹出“你的浏览器不支持XMLHTTP”的警告。

Note: The code above can be used every time you need to create an XMLHttpRequest object, so just copy and paste it whenever you need it.

备注：以上代码在你每次需要创建XMLHttpRequest对象时都要用到，所以在需要的任何时候拷贝粘贴在之前就可以。

The next chapter shows how to use the XMLHttpRequest object to communicate with a server.

下一章节我们将展示怎样用XMLHttpRequest对象去跟服务器沟通。

AJAX - More about the XMLHttpRequest object
AJAX-更多关于XMLHttpRequest对象
Before sending data off to a server, we will look at three important properties of the XMLHttpRequest object.

在给服务器发送数据之前，我们来看XMLHttpRequest对象的3个重要属性。


--------------------------------------------------------------------------------

The onreadystatechange property
onreadystatechange属性
After a request to a server, we need a function to receive the data returned from the server.

当请求服务器之后，我们需要一个函数去接受服务器返回的数据。

The onreadystatechange property stores the function that will process the response from a server. The function is stored in the property to be called automatically.

onreadystatechange属性存储函数将处理服务器端的响应。属性存储函数自动被唤醒存入相应属性。

The following code sets the onreadystatechange property and stores an empty function inside it:

如下代码设置了onreadystatechange属性并将空函数值存入之：

xmlhttp.onreadystatechange=function()
{
// We are going to write some code here

//我们将在此写入一些处理代码
}
 


--------------------------------------------------------------------------------

The readyState property
readyState属性
The readyState property holds the status of the server's response.

readyState属性持有服务器返回状态。

Each time the readyState property changes, the onreadystatechange function will be executed.

每当readyState属性改变，onreadystatechange函数就会被执行。

Possible values for the readyState property:

readyState属性的可能值：

State Description 
0 The request is not initialized 
1 The request has been set up 
2 The request has been sent 
3 The request is in process 
4 The request is complete 

状态值 描述 
0 请求未初始化 
1 请求已经建立 
2 请求已经发送 
3 请求中 
4 请求已完成 

Add an If statement to the onreadystatechange function to test if the response is complete (means that now we can get our data):

增加一个If语言去触发onreadystatechange函数去测试响应是否已经完成（意味着我们现在已经可以得到我们的数据了）：

xmlhttp.onreadystatechange=function()
{
if(xmlhttp.readyState==4)
　{ 
　// Get data from the server's response 

　//从服务器响应中获取数据
　} 
}
 


--------------------------------------------------------------------------------

The responseText property
responseText属性（响应文本属性）
The data sent back from a server can be retrieved with the responseText property.

responseText属性能够回收服务器端返回的数据。

Now, we want to set the value of the "Time" input field equal to responseText:

现在，我们将给“Time”赋值为输入框中返回文本（responseText）

xmlhttp.onreadystatechange=function()
{
if(xmlhttp.readyState==4)
　{ 
　document.myForm.time.value=xmlhttp.responseText; 
　} 
} 

The next chapter shows how to ask a server for data!

下一章节我们将展示如何向服务器索要数据！

AJAX - Request a Server
AJAX-请求服务器
  
--------------------------------------------------------------------------------

AJAX - Sending a request to a server
AJAX-向服务器端发送请求
To send off a request to the server, we use the open() and send() methods.

我们利用open()和send()方法向服务器发送请求。

The open() method takes three arguments. The first argument defines which method to use when sending the request (GET or POST). The second argument specifies the URL of the server-side script. The third argument specifies that the request should be handled asynchronously.

open()方法带有3个参数。第一个参数定义我们发送请求的方法类型（GET或POST）。第二个参数指定服务器端处理脚本的URL。第三个参数指定异步处理的请求。

The send() method sends the request off to the server. If we assume that the HTML and ASP file are in the same directory, the code would be: 

send()方法发送请求至服务器端。如果假设我们把HTML和ASP文件放在同一目录下，代码就应该是：

xmlhttp.open("GET","time.asp",true);
xmlhttp.send(null); 

Now we must decide when the AJAX function should be executed.

现在我们必须决定什么时候开始让AJAX函数执行了。

We will let the function run "behind the scenes" when a user types something in the "Name" field:

当我们在“Name”字段输入信息时，我们将让函数“在幕后”运行。

&lt;form name="myForm"&gt;
Name: &lt;input type="text" name="username" onkeyup="ajaxFunction();" /&gt;
Time: &lt;input type="text" name="time" /&gt;
&lt;/form&gt; 

Our updated "testAjax.htm" file now looks like this:

我们现在更新“testAjax.htm”文件如下：

&lt;html&gt;
&lt;body&gt;

&lt;script type="text/javascript"&gt;
function ajaxFunction()
{
var xmlhttp;
if (window.XMLHttpRequest)
　{ 
　// code for IE7+, Firefox, Chrome, Opera, Safari 
　xmlhttp=new XMLHttpRequest(); 
　} 
　else if (window.ActiveXObject)
　{ 
　// code for IE6, IE5 
　xmlhttp=new ActiveXObject( "Microsoft.XMLHTTP");
　} 
　else
　　{ 
　　alert( "Your browser does not support XMLHTTP!");
　　} 
xmlhttp.onreadystatechange=function()
{
　if(xmlhttp.readyState==4)
　{ 
　document.myForm.time.value=xmlhttp.responseText; 
　} 
}
xmlhttp.open("GET","time.asp",true);
xmlhttp.send(null);
}
&lt;/script&gt;

&lt;form name="myForm"&gt;
Name: &lt;input type="text" name="username" onkeyup="ajaxFunction();" /&gt;
Time: &lt;input type="text" name="time" /&gt;
&lt;/form&gt;

&lt;/body&gt;
&lt;/html&gt; 

The next chapter makes our AJAX application complete with the "time.asp" script.

下一章节我们将用“time.asp”脚本完成AJAX程序。

</content>
<bookmark>6120</bookmark>
</TextBean><TextBean UUID="a32557baed9c4e0daec6518a8c87cb4a">
<name>Job List</name>
<content>1.Cubic Batch Mapping

2.Oracle

3.Linux</content>
<bookmark>0</bookmark>
</TextBean><TextBean UUID="f9aa15212f5a490284331e6c7e71eede">
<name>用Lucene建立索引</name>
<content>索引的建立

索引的优化

索引的同步机制

简单的api后隐藏着更为复杂的结果

Lucene建立索引的步骤：

提取文本；构建Document；分析；建立索引；

1.提取文本：提取文本信息构建Document和Field

2.构建Document：将前面提取出来的文本组装成LUcene可以识别的格式来为索引建立做准备

3.分析并检索：提取LUcene建立索引的数据并且创建了Document后，调用IndexWriter类的addDocument()方法使LUcene建立索引，先对建立索引的数据进行分析（analysis），索引器按LUcene规定的索引格式将数据写入索引文件？


10.2 Lucene的文档格式

Document：（内容集合）

数据源：文件名、文件内容、文件的最后修改时间等

“文件名”、“文件内容”等名称可以看成是对不同数据源进行分类的标记，标记称为Field？

Lucene的Document代表一个需要进行索引的"单元"，任何需要进行索引的“文件”都必须被转化成Document对象?怎么转化 doc.add(......)? 才能够被索引和搜索到。Document doc = new Document(); 

任何数据源经过组织都可以够新建成一个Document类型，可以把Document对象看成一种虚拟文件，它自身带有多个数据源（某个东西的多个属性 例如 网页的标题、URL、内容—分别属于不同的Feild）。从文件能够提供数据源这个角度上来看，Document对象与实际的物理文件基本类似，不同之处仅仅在于LUcene无法识别普通的物理文件而只能识别一个Document类型的对象而已。

Document对象内部有一个Vector类型的对象数组，所有的Field保存其中，添加和删除Field就是对其内部的Vector进行操作。

Document不和任何类型的文件相关联   封装模式的体现 只需建立Document。


Field：

是否切割；是否索引；是否存储。

Field有两个属性可选：存储和索引。通过存储属性你可以控制是否对这个Field进行存储；通过索引属性你可以控制是否对该Field进行索引。这看起来似乎有些废话，事实上对这两个属性的正确组合很重要，下面

举例说明： 
还是以刚才的文章为例子，我们需要对标题和正文进行全文搜索，所以我们要把索引属性设置为真，同时我们希望能直接从搜索结果中提取文章标题，所以我们把标题域的存储属性设置为真，但是由于正文域太大了，我们为了缩小索引文件大小，将正文域的存储属性设置为假，当需要时再直接读取文件；我们只是希望能从搜索解果中提取最后修改时间，不需要对它进行搜索，所以我们把最后修改时间域的存储属性设置为真，索引属性设置为假。上面的三个域涵盖了两个属性的三种组合，还有一种全为假的没有用到，事实上Field不允许你那么设置，因为既不存储又不索引的域是没有意义的。 

1.1 Field 的解释
从源代码中，可以看出Field 构造函数如下：


Field(String name, byte[] value, Field.Store store)
Field(String name, Reader reader)
Field(String name, Reader reader, Field.TermVector termVector)
Field(String name, String value, Field.Store store, Field.Index index)
Field(String name, String value, Field.Store store, Field.Index index, Field.TermVector termVector)

在Field当中有三个内部类：Field.Index,Field.Store,Field.termVector。其中

* Field.Index有四个属性，分别是：
Field.Index.TOKENIZED：分词索引
Field.Index.UN_TOKENIZED：分词进行索引，如作者名，日期等，Rod Johnson本身为一单词，不再需要分词。
Field.Index：不进行索引，存放不能被搜索的内容如文档的一些附加属性如文档类型, URL等。
Field.Index.NO_NORMS：；
* Field.Store也有三个属性，分别是：
Field.Store.YES：索引文件本来只存储索引数据, 此设计将原文内容直接也存储在索引文件中，如文档的标题。
Field.Store.NO：原文不存储在索引文件中，搜索结果命中后，再根据其他附加属性如文件的Path，数据库的主键等，重新连接打开原文，适合原文内容较大的情况。
Field.Store.COMPRESS 压缩存储；
* termVector是Lucene 1.4.3新增的它提供一种向量机制来进行模糊查询,很少用。
1.1 Field 的解释
从源代码中，可以看出Field 构造函数如下：
Field(String name, byte[] value, Field.Store store)
Field(String name, Reader reader)
Field(String name, Reader reader, Field.TermVector termVector)
Field(String name, String value, Field.Store store, Field.Index index)
Field(String name, String value, Field.Store store, Field.Index index, Field.TermVector termVector)

在Field当中有三个内部类：Field.Index,Field.Store,Field.termVector。其中

* Field.Index有四个属性，分别是：
Field.Index.TOKENIZED：分词索引 analysis?
Field.Index.UN_TOKENIZED：分词进行索引，如作者名，日期等，Rod Johnson本身为一单词，不再需要分词。不同？
Field.Index：不进行索引，存放不能被搜索的内容如文档的一些附加属性如文档类型, URL等。
Field.Index.NO_NORMS：；


* Field.Store也有三个属性，分别是：
Field.Store.YES：索引文件本来只存储索引数据, 此设计将原文内容直接也存储在索引文件中，如文档的标题。
Field.Store.NO：原文不存储在索引文件中，搜索结果命中后，再根据其他附加属性如文件的Path，数据库的主键等，重新连接打开原文，适合原文内容较大的情况。
Field.Store.COMPRESS 压缩存储；
* termVector是Lucene 1.4.3新增的它提供一种向量机制来进行模糊查询,很少用。

上面所说的Field属性与lucene1.4.3版本的有比较大的不同，在旧版的1.4.3里lucene是通过Field.Keyword (...),FieldUnIndexed(...),FieldUnstored(...)和Field.Text(...)来设置不同字段的类型以达 到不同的用途，而当前版本由Field.Index和Field.Store两个字段的不同组合来达到上述效果。
还有一点说明,其中的两个构造函数其默认的值为Field.Store.NO和Field.Index.TOKENIZED。：

Field(String name, Reader reader)
Field(String name, Reader reader, Field.TermVector termVector)

col:Store, row:Index YES NO COMPRESS 
NO 存储，但是不建立索引，当然也就不分析。这样的字段无法搜索，但是会出现在搜索结果中。 无意义。引发Illegal Argument Exception。 基本等同于YES，但是外加了压缩。对于较长的文本和二进制的字段，应该选用这个参数。计算量更大。 
ANALYZED 分析，索引，存储。 分析，索引，不存储。 分析，索引，压缩存储。 
NOT_ANALYZED 不分析，但是索引，存储。 不分析，直接索引，但是不存储。 不分析，但是索引，压缩存储。 
NOT_ANALYZED_NO_NORMS （高级） （高级） （高级） 
ANALYZED_NO_NORMS （高级） （高级） （高级） 


不被切割、被索引并完整保存：链接地址URLs、文件系统路径信息、时间日期、人名、居民身份证、号码、电话号码。

不被切割、不被索引、存储：网页的URL引用地址。

被切割、被索引、不存储：不需要以原有的形式来重现原始数据的大规模文本，比如网页的主体部分或者是庞大的文本文档。

Field可以构造自己的构造函数

IndexWriter：将文档加入索引，同时控制索引过程中各种参数

IndexWriter构造函数包括以下三个参数：                                                                                      

1.索引存放的路径：这个路径可以是一个 String型的目录位置，也可以是经过封装的java.io.File对象，同时还可以是Lucene自带的Directory类型的对象。

2.分析器：IndexWriter构造函数中不可缺少的一项就是一个继承自org.apache.lucene.analysis.Analyzer的分析器，它的主要功能是在IndexWriter将文档写入索引前，把文本信息切分成一个个可以进行索引的词条。

3.是否重新创建索引，True 一律清空 重新建立 False 原有基础上增量添加索引



注意：通常情况下，在一段代码中要把文档索引写入某个目录时，只能生明一个IndexWriter的对象，这是由于多个IndexWriter对象同时网通一个目录中写索引时，会出现很严重的同步问题。

向索引添加文档：Lucene借助INdexWriter向索引添加数据 拥有若干个Document添加进索引

IndexWriter writer = new IndexWriter(path,new StandardAnalysis,true);

try { writer.addDocument(doc 1);     -----------------------------------------------------------------------------------doc.add(new Field("name","value",Field.Store.YES,Field.INDEX.ANALYZED))

       writer.close; 调用close方法后，索引器才会将存放于内存中的所有内容写入磁盘并关闭输出流？

先添加入内存中吗？

} catch (IOException e) {

e.printStackTrace();

}

重复使用IndexWriter的addDocument方法完成一切建立索引的过程

调整性能参数：

IndexWriter类不仅能建立索引，同时，还可以对索引过程中的一些性能参数进行控制。整个缩影过程中，几乎全部时间都会花再把索引从内存中写入磁盘以及合并不同的Segement中。根据服务器机器状态修改于调整。

1.mergeFactor：用于控制Lucene在把索引从内存写入磁盘上的文件系统时内存中最大的Document数量，同时控制内存中最大的Segment数量。mergeFactor=10，当IndexWriter为第11个Document建立索引时，他就会新建一个Segment。当磁盘上Segment数量达到10，合并。会影响到Lucene建立索引时花费的磁盘I/O时间和内容

索引过程优化

索引一般分2种情况，一种是小批量的索引扩展，一种是大批量的索引重建。在索引过程中，并不是每次新的DOC加入进去索引都重新进行一次索引文件的写入操作（文件I/O是一件非常消耗资源的事情）。

Lucene先在内存中进行索引操作，并根据一定的批量进行文件的写入。这个批次的间隔越大，文件的写入次数越少，但占用内存会很多。反之占用内存少，但文件IO操作频繁，索引速度会很慢。在IndexWriter中有一个MERGE_FACTOR参数可以帮助你在构造索引器后根据应用环境的情况充分利用内存减少文件的操作。根据我的使用经验：缺省Indexer是每20条记录索引后写入一次，每将MERGE_FACTOR增加50倍，索引速度可以提高1倍左右。

2.maxMergeDocs

当要建立索引的文档数量太大的话，一个Segment中的文档数量可能会相当庞大，会严重影响到索引的速度。他们使用maxMergeDocs来限制一个Segement中最大的文档数量。一个较大的maxMergeDocs适用于应对大批量的文档搜索建立（减少I/O），增量式的索引则应使用较小的maxMergeDocs。

3.minMergeDocs

用于控制内存中持有的文档数量，对磁盘上的Segment大小没有任何影响

限制Field的长度

比如用户为一篇100万字的文章建立索引，可能后10万字都是附录，限制最大的字段长度。

maxFieldLength属性的默认值为10000，Lucene仅仅索引文档的前10000个term，可以重置？

Segment：

Segment是Lucene索引文件的最基本的一个单位，一个Segment就是一个独立的索引，可以由IndexWriter进行单独的查找，Lucene不同的往磁盘中加入新的Segment，合并。

Segments——多少个Segment。

复合索引：setUseCompound(boolean)通过它可以设置是否使用复合索引格式，默认值为复合索引

10.5索引的存放位置——FSDirectory RAMDirectory

索引存放位置：磁盘和内存 IndexWriter（Directory d,Analyzer a,bolean creat）;

在磁盘中存放——FSDirectory   File System Directory Lucene会自动在内存中建立缓存，然后到一定时候就将索引写入磁盘。

IndexWriter writer = new IndexWriter(FSDirectory.getDirectory(path),new StandardAnalyzer(),true);

在内存中存储——虚拟机退出后，内存中的索引将不复存在。

IndexWriter writer = new IndexWriter(new RAMDirectory(),new StandardAnalyzer(),true);

10.5.3索引的合并

当开发者在不同地方传见了许多索引之后，进行索引合并，IndexWriter中的addIndexes()方法。

创建文件系统的索引目录

writerram.addDocument(doc1);
writerdir.addDocument(doc2);
        
writerram.close();

writerdir.addIndexes(new Directory[]{dir}); 

先关闭ramWriter,以使所有的文档都进入RAMDirectory。

10.6从索引中删除文档

删除索引的工具——IndexReader类 

reader.deleteDocuments(new Term("name","world2"));新建一个Term 删除 Field里含有world2的文档。

reader.deleteDocument(int number);删除文档编号number的文档——不友好。

10.7Lucene的索引优化

合并磁盘上的索引文件，以减少文件数量，从而减少搜索索引时间

optimize()——将磁盘上的多个Segment进行合并，组成一个全新的Segment，该方法不应当在索引建立的过程中被调用，而是在对大批量索引建立完成后再进行调用，优化时，磁盘的I/O操作频繁
</content>
<bookmark>2237</bookmark>
</TextBean><TextBean UUID="42394654b3e946f4ae814c3853417b62">
<name>Lucene搜索方法总结1</name>
<content>1.多字段搜索
使用 multifieldqueryparser 可以指定多个搜索字段。

query query = multifieldqueryparser.parse(”name*”, new string[] { fieldname, fieldvalue }, analyzer);

indexreader reader = indexreader.open(directory);

indexsearcher searcher = new indexsearcher(reader);

hits hits = searcher.search(query);

 

2.多条件搜索
除了使用 queryparser.parse 分解复杂的搜索语法外，还可以通过组合多个 query 来达到目的。

query query1 = new termquery(new term(fieldvalue, “name1′)); // 词语搜索

query query2 = new wildcardquery(new term(fieldname, “name*”)); // 通配符 

//query query3 = new prefixquery(new term(fieldname, “name1′)); // 字段搜索 field:keyword，自动在结尾添加 *

//query query4 = new rangequery(new term(fieldnumber, numbertools.longtostring(11l)), new term(fieldnumber, numbertools.longtostring(13l)), true); // 范围搜索

//query query5 = new filteredquery(query, filter); // 带过滤条件的搜索

booleanquery query = new booleanquery();

query.add(query1, booleanclause.occur.must);

query.add(query2, booleanclause.occur.must);

indexsearcher searcher = new indexsearcher(reader);

hits hits = searcher.search(query);

 

3.过滤
使用 filter 对搜索结果进行过滤，可以获得更小范围内更精确的结果。

举个例子，我们搜索上架时间在 2005-10-1 到 2005-10-30 之间的商品。

对于日期时间，我们需要转换一下才能添加到索引库，同时还必须是索引字段。 // index

document.add(fielddate, datefield.datetostring(date), field.store.yes, field.index.un_tokenized);

//…

// search

filter filter = new datefilter(fielddate, datetime.parse(”2005-10-1′), datetime.parse(”2005-10-30′));

hits hits = searcher.search(query, filter);

除了日期时间，还可以使用整数。比如搜索价格在 100 ~ 200 之间的商品。

lucene.net numbertools 对于数字进行了补位处理，如果需要使用浮点数可以自己参考源码进行。 // index

document.add(new field(fieldnumber, numbertools.longtostring((long)price), field.store.yes, field.index.un_tokenized));

//…

// search

filter filter = new rangefilter(fieldnumber, numbertools.longtostring(100l), numbertools.longtostring(200l), true, true);

hits hits = searcher.search(query, filter);

使用 query 作为过滤条件。 queryfilter filter = new queryfilter(queryparser.parse(”name2′, fieldvalue, analyzer));

我们还可以使用 filteredquery 进行多条件过滤。

filter filter = new datefilter(fielddate, datetime.parse(”2005-10-10′), datetime.parse(”2005-10-15′));

filter filter2 = new rangefilter(fieldnumber, numbertools.longtostring(11l), numbertools.longtostring(13l), true, true);

query query = queryparser.parse(”name*”, fieldname, analyzer);

query = new filteredquery(query, filter);

query = new filteredquery(query, filter2);

indexsearcher searcher = new indexsearcher(reader);

hits hits = searcher.search(query);

 

4.分布搜索
我们可以使用 multireader 或 multisearcher 搜索多个索引库。

multireader reader = new multireader(new indexreader[] { indexreader.open(@”c:\index”), indexreader.open(@”\\server\index”) });

indexsearcher searcher = new indexsearcher(reader);

hits hits = searcher.search(query);

或

indexsearcher searcher1 = new indexsearcher(reader1);

indexsearcher searcher2 = new indexsearcher(reader2);

multisearcher searcher = new multisearcher(new searchable[] { searcher1, searcher2 });

hits hits = searcher.search(query);

还可以使用 parallelmultisearcher 进行多线程并行搜索。

 

5.显示搜索语法字符串
我们组合了很多种搜索条件，或许想看看与其对等的搜索语法串是什么样的。 booleanquery query = new booleanquery();

query.add(query1, true, false);

query.add(query2, true, false);

//…

console.writeline(”syntax: {0}”, query.tostring());

输出：

syntax: +(name:name* value:name*) +number:[0000000000000000b to 0000000000000000d]

呵呵，就这么简单。

 

6.如何删除索引
lucene提供了两种从索引中删除document的方法，一种是

 

void deleteDocument(int docNum)

 

这种方法是根据document在索引中的编号来删除，每个document加进索引后都会有个唯一编号，所以根据编号删除是一种精确删除，但是这个编号是索引的内部结构，一般我们不会知道某个文件的编号到底是几，所以用处不大。另一种是

 

void deleteDocuments(Term term)

 

这种方法实际上是首先根据参数term执行一个搜索操作，然后把搜索到的结果批量删除了。我们可以通过这个方法提供一个严格的查询条件，达到删除指定document的目的。

下面给出一个例子：

 

Directory dir = FSDirectory.getDirectory(PATH, false);

IndexReader reader = IndexReader.open(dir);

Term term = new Term(field, key);

reader.deleteDocuments(term);

reader.close();

 

ms还有操作

deleteDocuments(Term);   
deleteDocuments(Term[]);   
deleteDocuments(Query);   
deleteDocuments(Query[]);  

 

 



 

7.如何更新索引
注：据多人反应，新版本的lucene以及提供了更新索引的方法。

writer.updateDocument(doc); 


————————————————————javaeye分割线——————————————

 

lucene并没有提供专门的索引更新方法，我们需要先将相应的document删除，然后再将新的document加入索引。例如：

 

Directory dir = FSDirectory.getDirectory(PATH, false);

IndexReader reader = IndexReader.open(dir);

Term term = new Term(“title”, “lucene introduction”);

reader.deleteDocuments(term);

reader.close();

 

IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(), true);

Document doc = new Document();

doc.add(new Field("title", "lucene introduction", Field.Store.YES, Field.Index.TOKENIZED));

doc.add(new Field("content", "lucene is funny", Field.Store.YES, Field.Index.TOKENIZED));

writer.addDocument(doc);

writer.optimize();

writer.close();

 




 


 

 

8.多样化的搜索
 

/** *** 一个关键字，对一个字段进行查询 **** */

QueryParser qp = new QueryParser("content",analyzer);

query = qp.parse(keyword);

Hits hits = searcher.search(query);

 

/** *** 模糊查询 **** */

Term term = new Term("content",keyword);

FuzzyQuery fq = new FuzzyQuery(term);

Hits hits = searcher.search(fq);

 

/** *** 一个关键字，在两个字段中查询 **** */

/*

 * 1.BooleanClause.Occur[]的三种类型： MUST : + and MUST_NOT : - not SHOULD : or

 * 2.下面查询的意思是：content中必须包含该关键字，而title有没有都无所谓

 * 3.下面的这个查询中，Occur[]的长度必须和Fields[]的长度一致。每个限制条件对应一个字段

 */

BooleanClause.Occur[] flags = new BooleanClause.Occur[]{BooleanClause.Occur.SHOULD,BooleanClause.Occur.MUST};

query=MultiFieldQueryParser.parse(keyword,new String[]{"title","content"},flags,analyzer);

 

 

/** *** 两个(多个)关键字对两个(多个)字段进行查询,默认匹配规则 **** */

/*

 * 1.关键字的个数必须和字段的个数相等 

 * 2.由于没有指定匹配规定，默认为"SHOULD" 因此，下面查询的意思是："title"中含有keyword1 或 "content"含有keyword2. 

 * 在此例中，把keyword1和keyword2相同

 */

 query=MultiFieldQueryParser.parse(new String[]{keyword,keyword},new

 String[]{"title","content"},analyzer);

 

 

/** *** 两个(多个)关键字对两个(多个)字段进行查询,手工指定匹配规则 **** */

/*

 * 1.必须 关键字的个数 == 字段名的个数 == 匹配规则的个数

 * 2.下面查询的意思是："title"必须不含有keyword1,并且"content"中必须含有keyword2

 */

 BooleanClause.Occur[] flags = new

 BooleanClause.Occur[]{BooleanClause.Occur.MUST_NOT,BooleanClause.Occur.MUST};

 query=MultiFieldQueryParser.parse(new String[]{keyword,keyword},new

 String[]{"title","content"},flags,analyzer);

 

 

/** *** 对日期型字段进行查询 **** */

 

/** *** 对数字范围进行查询 **** */

/*

 * 1.两个条件必须是同一个字段 

 * 2.前面一个条件必须比后面一个条件小，否则找不到数据

 *  3.new RangeQuery中的第三个参数，表示是否包含"=" true: &gt;= 或 &lt;= false: &gt; 或 &lt; 

 * 4.找出 55&gt;=id&gt;=53 or 60&gt;=id&gt;=57:

 */

Term lowerTerm1 = new Term("id","53");

Term upperTerm1 = new Term("id","55");

RangeQuery rq1 = new RangeQuery(lowerTerm1,upperTerm1,true);

 

Term lowerTerm2 = new Term("id","57");

Term upperTerm2 = new Term("id","60");

RangeQuery rq2 = new RangeQuery(lowerTerm2,upperTerm2,true);

 

BooleanQuery bq = new BooleanQuery();

bq.add(rq1,BooleanClause.Occur.SHOULD);

bq.add(rq2,BooleanClause.Occur.SHOULD);

Hits hits = searcher.search(bq);

 

9.结果排序  
排序的关键点有两个：

 

1:首先你要排序的字段必须是被index的，并且是untokenized的。

 

如：

 

doc.add(new Field("click", dv.get("click").toString(), Field.Store.NO, Field.Index.UN_TOKENIZED));

2：在检索时候：

 

如：   

  

   /*****  排序  *****/

   /*

    * 1.被排序的字段必须被索引过(Indexecd)，在索引时不能 用 Field.Index.TOKENIZED

    *   (用UN_TOKENIZED可以正常实现.用NO时查询正常，但排序不能正常设置升降序)

    * 2.SortField类型

    *   SCORE、DOC、AUTO、STRING、INT、FLOAT、CUSTOM 此类型主要是根据字段的类型选择

    * 3.SortField的第三个参数代表是否是降序true:降序  false:升序

    */

   Sort sort = new Sort(new SortField[]{new SortField("click", SortField.INT, true)});

   Hits hits = searcher.search(querystring,sort);

   

    /*

    * 按日期排序

    */

   Sort sort = new Sort(new SortField[]{new SortField("createTime", SortField.INT, false)});

 

    

    /*****  过滤器 ******/

   QueryParser qp1 = new QueryParser("content",analyzer);

   Query fquery  = qp1.parse("我");

   

   BooleanQuery bqf = new BooleanQuery();

   bqf.add(fquery,BooleanClause.Occur.SHOULD);

    

   QueryFilter qf = new QueryFilter(bqf);

   

   Hits hits = searcher.search(query);

 

10.将小索引文件合并到大的索引文件中去(此方法性能不佳)
/** 将小索引文件合并到大的索引文件中去 

  *   @param   from   将要合并到to文件的文件 

  *   @param   to       将from文件合并到该文件 

  *   @param   analyzer   

  */ 

private   void   mergeIndex(File   from,File   to,Analyzer   analyzer) 

{ 

IndexWriter   indexWriter   =   null; 

try{ 

System.out.println("正在合并索引文件!\t"); 

indexWriter   =   new   IndexWriter(to,analyzer,   false); 

indexWriter.setMergeFactor(100000); 

indexWriter.setMaxFieldLength(Integer.MAX_VALUE); 

indexWriter.setMaxBufferedDocs(Integer.MAX_VALUE); 

indexWriter.setMaxMergeDocs(Integer.MAX_VALUE); 

FSDirectory[]   fs   =   {FSDirectory.getDirectory(from,false)}; 

indexWriter.addIndexes(fs); 

indexWriter.optimize(); 

indexWriter.close(); 

System.out.println("已完成合并!\t"); 

} 

catch(Exception   e) 

{ 

Utility.writeLog("合并索引文件出错！mergeIndex()"+e.getMessage(),""); 

} 

finally 

{ 

try{ 

if(indexWriter!=null) 

indexWriter.close(); 

} 

catch(Exception   e   ){ 

 

} 

 

} 

 

} 

 

合并时间是从每天的凌晨3点钟开始,一直到早上9点左右,足足用5个小时才合并完成,其中大索引文件大小为4G,小索引为10MB.

 

 

11.问题2：单字共现频率的局部统计的原理
解答：

 

高频字串统计的理论基础是N - 元模型。

设W1 W2 ...WN 是长度为N 的字串,则字串W 的似然度为
p ( W) = p ( w i | w1 w2 ...w i - 1) (1)
上面公式的意义反映连续个N 字之间的结合程度,如果若干种不同的历史组合W1 W2 ...WN的最后N - 1 个字相同,就把它们都看作一类。在这一假设下,每一个字出现的概率不再与前面的历史有关,只与最近的N - 1 个字相关,字串的先验概率为
p ( W) = p ( w i - ( n - 1) w i - ( n - 2) ...w i - 1) (2)
当p ( W) 超过一定的阈值时,说明这N 个字的结合能力较强,我们就可以认为该字串能被看成一个“词”。

正是根据以上所说原理，预先对待分词文本每个单字进行出现次数统计并记录它们在文中出现的位置（存储方式如附件图例所示），预处理后我们遍历单字频次统计 列表出现次数大于2的所有单字在文中出现的位置i，判断位置i+1的单字出现次数是否也大于2，若是则判断位置i+2的单字出现次数是否也大于2，如此类 推直至位置i+n+1的单字出现次数小于2，获得候选词组 w(i,i+1...i+n)并放入候选词汇集合，最后对候选词汇集合进行前缀后缀处理获得合适的高频词汇集合result



12.索引合并
writer.addIndexes(indexDirs); 
</content>
<bookmark>1463</bookmark>
</TextBean><TextBean UUID="e66bd820ace0465e96a5e90378feb9a8">
<name>Lucene搜索方法总结2</name>
<content>1.    排序
1.1. Sort类
public Sort()

public Sort(String field)

public Sort(String field,Boolean reverse)  //默认为false，降序排序

public Sort(String[] fields)

public Sort(SortField field)

public Sort(SortField[] fields)

Sort sort=new Sort(“bookname”);按照“bookname“这个Field值进行降序排序

Sort sort=new Sort(“bookname”,true) //升序排序

Sort sort=new Sort(new String[]{“bookNumber”,”bookname”,”publishdate”});按照三个Field进行排序，但无法指定升序排序，所以用SortField

1.2. SortField类
public SortField(String field)

public SortField(String field,Boolean reverse)

public SortField(String field,int type) //type表示当前Field值的类型

public SortField(String field,int type,boolean reverse)  //默认为false，升序

Field值的类型：SortField.STRING、SortField.INT、SortField.FLOAT

SortField sf1=new SortField(“bookNumber”,SortField.INT,false);

SortField sf2=new SortField(“bookname”,SortField.STRING,false);

1.3. 指定排序的法则
1.3.1.按照文档的得分降序排序
Hits hits=searcher.search(query,Sort.RELEVANCE);

1.3.2.按文档的内部ID升序排序
Hits hits=searcher.search(query, Sort.INDEXORDER);

1.3.3.按照一个Field来排序
Sort sort=new Sort();

SortField sf=new SortField(“bookNumber”,SortField.INT,false);

sort.setSort(sf);

Hits hits=searcher.search(query,sort);

1.3.4.按照多个Field来排序
Sort sort=new Sort();

SortField sf1=new SortField(“bookNumber”,SortField.INT,false);//升序

SortField sf2=new SortField(“publishdate”,SortField.STRING,true);//降序

sort.setSort(new SortField[]{sf1,sf2});

Hits hits=searcher.search(query,sort);

1.3.5.改变SortField中的Locale信息
String str1=”我”; String str2=”你”;

Collator co1=Collator.getInstance(Locale.CHINA);

Collator co2=Collator.getInstance(Locale.JAPAN);

System.out.println(Locale.CHINA+”:”+co1.compare(str1，str2));

System.out.println(Locale.JAPAN+”:”+co2.compare(str1,str2));

输出结果为：

zh_CN:1

ja_JP:-1

所以

public SortField(String field,Locale locale)

public SortField(String field,Locale locale,boolean reverse)

2.    过滤器
使用public Hits search(Query query,Filter filter)

（1）简单过滤

Hits hits=searcher.search(query,new AdvancedSecurityFilter());//过滤掉securitylevel为0的结果

（2）范围过滤—RangeFilter

只显示中间的

RangeFilter filter=new RangeFilter(“publishdate”,”1970-01-01”,”1998-12-31”,true,true”);

Hits hits=searcher.search(query,filter);

 

无上边界

public static RangeFilter More(String fieldname,String lowerTerm)

 

无下边界

public static RangeFilter Less(String fieldname,String upperTerm)

(3)在结果中查询QueryFilter

RangeQuery q=new RangeQuery(new Term(“publicshdate”,”1970-01-01”),

new Term(“publishdate”,”1999-01-01”),true);

QueryFilter filter=new QueryFilter(q);

Hits hits=searcher.search(query,filter);

3.    分析器Analysis
3.1. 自带分析器和过滤器
Ø         标准过滤器：StandardAnalyzer

Ø         大小写转换器：LowerCaseFilter

Ø         忽略词过滤器：StopFilter

public StopFilter(TokenStream input,String [] stopWords)

public StopFilter(TokenStream in,String [] stopWords,boolean ignoreCase)

public StopFilter(TokenStream input,Set stopWords,boolean ignoreCase)

public StopFilter(TokenStream in, Set stopWords)

其中，参数TokenStream代表当前正在进行处理的流；String类型的数组代表一个用数组表示的忽略词集合；Set类型的参数与String一样，是用来表示忽略词集合的；boolean表示当与忽略词集合中的词进行匹配时，是否需要忽略大小写。

Ø         长度过滤器：LengthFilter

Ø         PerFieldAnalyzerWrapper

Ø         WhitespaceAnalyzer

String str="str1 str2 str3";

       StringReader reader=new StringReader(str);

       Analyzer anlyzer=new WhitespaceAnalyzer();

       

       TokenStream ts=anlyzer.tokenStream("", reader);

       Token t=null;

       while( (t=ts.next())!=null ){

           System.out.println(t.termText());

       }

3.2. 第三方过分析器
Ø         单字分词

Ø         二分法：CJKAnalyzer、中科院ICTCLAS分词、JE分词

Ø         词典分词

3.2.1.JE分词用法
3.2.1.1.    示例
import jeasy.analysis.MMAnalyzer;

IndexWriter writer = new IndexWriter(INDEX_STORE_PATH, new MMAnalyzer()

, true);

String str=" Lucene是一个全文检索引擎的架构，"+

           "提供了完整的查询引擎和索引引擎。Lucene以其方便使用、快" +

           "速实施以及灵活性受到广泛的关注。它可以方便地嵌入到各种应用" +

           "中实现针对应用的全文索引、检索功能，本总结使用lucene--2.3.2。";

       MMAnalyzer analyzer=new MMAnalyzer();

       try{

           System.out.println(analyzer.segment(str, "|"));

       }

       catch(Exception e)

       {

           e.printStackTrace();

       }

输出结果：lucene|一个|全文|检索|引擎|架构|提供|完整|查询|。。。。

3.2.1.2.    设定正向最大匹配的字数
MMAnalyzer analyzer=new MMAnalyzer(4);

3.2.1.3.    添加新词
MMAnalyzer.addWord(String word);

MMAnalyzer.addDictionary(Reader reader);

 

MMAnalyzer analyzer=new MMAnalyzer();

MMAnalyzer.addWord("迈克尔雷第");

 

4.    索引的合并
RAMDirectory RAMDir=new RAMDirectory();

IndexWriter writer = new IndexWriter(RAMDir, new StandardAnalyzer(), true);//删除原有索引

IndexWriter writer2=new IndexWriter(FSDirectory.getDirectory(path,true),

new StandardAnalyzer(), true);

writer.addDocument(doc1);

writer2.addDocument(doc2);

writer.close();

writer2.addIndexes(new Directory[]{RAMDir});

writer2.close();

注意：在合并前一定要先关闭要加的索引器。



本文来自CSDN博客，转载请标明出处：http://blog.csdn.net/xiaoping8411/archive/2010/03/24/5413738.aspx</content>
<bookmark>0</bookmark>
</TextBean><TextBean UUID="3bff8998741046b9a29a5d4f19552e63">
<name>MultiFieldQueryParser和BooleanQuery</name>
<content>import java.io.IOException; 
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.index.CorruptIndexException;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.Term;
import org.apache.lucene.queryParser.MultiFieldQueryParser;
import org.apache.lucene.search.BooleanClause;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.Hits;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.TermQuery;

/**
* 与或非布尔查询——Lucene中的BooleanQuery
* @author USER
*
*/
public class TestBooleanQuery {
   /**
    * 主函数，运行测试程序
    * @param args
    * @throws Exception
    */
public static void main(String[] args) throws Exception {    
     //建索引
   createIndex();    
       
   //多个TermQuery构建BooleanQuery检索
      searchIndex4TermQuery();
     
     //一个MultiFieldQueryParser构建BooleanQuery多个域的检索
     searchIndex4MultiFieldQueryParser();
   }    
     
/**
* 建索引
* @throws Exception
*/
   public static void createIndex() throws Exception {    
     Document doc1 = new Document();    
     Field field = null;    
     field = new Field("name", "word1 word2 word3", Field.Store.YES,    
         Field.Index.TOKENIZED);    
     doc1.add(field);    
     field = new Field("title", "doc1", Field.Store.YES, Field.Index.TOKENIZED);    
     doc1.add(field);    
    
     Document doc2 = new Document();    
     field = new Field("name", "word4 word5", Field.Store.YES,    
         Field.Index.TOKENIZED);    
     doc2.add(field);    
     field = new Field("title", "doc2", Field.Store.YES, Field.Index.TOKENIZED);    
     doc2.add(field);    
    
     Document doc3 = new Document();    
     field = new Field("name", "word1 word2 word6", Field.Store.YES,    
         Field.Index.TOKENIZED);    
     doc3.add(field);    
     field = new Field("title", "doc3", Field.Store.YES, Field.Index.TOKENIZED);    
     doc3.add(field);    
    
     /**
      * 为测试MultiFieldQueryParser而添加的文档
      */
     Document doc4 = new Document();    
     field = new Field("name", "word1 word2 word3", Field.Store.YES,    
          Field.Index.TOKENIZED);    
     doc4.add(field);    
     field = new Field("title", "doc1 word1", Field.Store.YES, Field.Index.TOKENIZED);    
     doc4.add(field);
     
     /**
      * 对MultiFieldQueryParser更深理解
      */
     Document doc5 = new Document();    
     field = new Field("title", "北京2008年奥运会", Field.Store.YES,    
          Field.Index.TOKENIZED);    
     doc5.add(field);    
     field = new Field("name", "这是一届创造奇迹、超越梦想的.......", Field.Store.YES, Field.Index.TOKENIZED);    
     doc5.add(field);
     
     Document doc6 = new Document();    
     field = new Field("title", "北京2008年奥运会", Field.Store.YES,    
          Field.Index.TOKENIZED);    
     doc6.add(field);    
     field = new Field("name", "这是一届创造奇迹、超越梦想的奥运会.......", Field.Store.YES, Field.Index.TOKENIZED);    
     doc6.add(field);
     
     IndexWriter writer = new IndexWriter("e:\\java\\index",    
         new StandardAnalyzer(), true);    
     writer.addDocument(doc1);    
     writer.addDocument(doc2);    
     writer.addDocument(doc3); 
     
     writer.addDocument(doc4); 
     
     writer.addDocument(doc5);
     writer.addDocument(doc6);
     
     writer.close();    
   } 
   
   /**
    * 由TermQuery和BooleanQuery构建的多个域检索
    * @throws Exception
    */
   public static void searchIndex4TermQuery() throws Exception{
    TermQuery query1 = null;    
      TermQuery query2 = null;    
      TermQuery query3 = null;    
      TermQuery query4 = null;    
      TermQuery query5 = null; 
      TermQuery query6 = null; 
      BooleanQuery bquerymain = null;    
      BooleanQuery bquery1 = null;    
      BooleanQuery bquery2 = null;    
      BooleanQuery bquery3 = null;    
      Hits hits = null;    
     
      IndexSearcher searcher = new IndexSearcher("e:\\java\\index");    
     
      query1 = new TermQuery(new Term("name", "word1"));    
      query2 = new TermQuery(new Term("name", "word2"));    
       
      query3 = new TermQuery(new Term("name", "word3"));
      
      query4 = new TermQuery(new Term("name", "word4"));    
      query5 = new TermQuery(new Term("name", "word5"));    
          
      query6 = new TermQuery(new Term("name", "word6"));    
          
          
     
      // 构造布尔查询（可根据你的要求随意组合）    
      bquerymain = new BooleanQuery();    
      bquery1 = new BooleanQuery();    
      bquery2 = new BooleanQuery();    
      bquery3 = new BooleanQuery();    
     
      bquery1.add(query1, BooleanClause.Occur.MUST);    
      bquery1.add(query3, BooleanClause.Occur.MUST);    
          
      bquery2.add(query3, BooleanClause.Occur.MUST);    
      bquery2.add(query4, BooleanClause.Occur.MUST);    
          
      bquery3.add(query5, BooleanClause.Occur.MUST);
      bquery3.add(query6, BooleanClause.Occur.MUST_NOT); 
          
      bquerymain.add(bquery1, BooleanClause.Occur.SHOULD);    
      bquerymain.add(bquery2, BooleanClause.Occur.SHOULD);    
      bquerymain.add(bquery3, BooleanClause.Occur.MUST); 
      
      /**
       * 根据你的要求建一个BooleanQuery对象，然后来查询
       */
      hits = searcher.search(bquery3);&amp;nbs

p;   
      printResult(hits, bquery1.toString());    
     
   }
    
   /**
    * 由MultiFieldQueryParser和BooleanQuery构建的多个域检索
    * @throws Exception
    */
   public static void searchIndex4MultiFieldQueryParser() throws Exception{
      Hits hits = null;    
     
      IndexSearcher searcher = new IndexSearcher("e:\\java\\index");    
     
      // 构造布尔查询（可根据你的要求随意组合） 
      BooleanClause.Occur[] flags = new BooleanClause.Occur[] {
      BooleanClause.Occur.MUST, BooleanClause.Occur.MUST};
     
      Query query = MultiFieldQueryParser.parse("word1", new String[] {
      "name", "title"}, flags, new StandardAnalyzer());
     
    /* //加深对MultiFieldQueryParser的理解（注意看建索引的文档doc5,doc6与检索后的结果）
      Query query = MultiFieldQueryParser.parse("北京 奥运会", new String[] {
      "name", "title"}, flags, new StandardAnalyzer());    */
    
      hits = searcher.search(query);    
      printResult(hits, query.toString());    
     
   }
   
   /**
    * 打印输出检索出的文档，并输出检索的布尔语句
    * @param hits
    * @param key
    * @throws Exception
    */
   public static void printResult(Hits hits, String key) throws Exception {    
     System.out.println("查询 " + key);    
     if (hits != null) {    
       if (hits.length() == 0) {    
         System.out.println("没有找到任何结果");    
       } else {    
         System.out.println("找到" + hits.length() + "个结果");    
         for (int i = 0; i &lt; hits.length(); i++) {    
           Document d = hits.doc(i);    
           String dname = d.get("title");    
           System.out.print(dname + "   ");    
         }    
         System.out.println();    
         System.out.println();    
       }    
     }    
   }    
}   </content>
<bookmark>0</bookmark>
</TextBean></TextList>